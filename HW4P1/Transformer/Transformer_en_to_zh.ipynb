{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import jieba\n",
    "\n",
    "import sacrebleu\n",
    "import torchtext\n",
    "from typing import Tuple\n",
    "import torchdata\n",
    "import spacy\n",
    "from collections import Counter  # 计数器，用于统计词频\n",
    "from tqdm import tqdm  # 进度条库，用于显示进度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取数据集文件路径\n",
    "train_path = \"E:/project_2023/11785/fanyi/data/train.txt\"\n",
    "val_path = \"E:/project_2023/11785/fanyi/data/val.txt\"\n",
    "test_path = \"E:/project_2023/11785/fanyi/data/test.txt\"\n",
    "\n",
    "# 定义批处理大小。\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, source_tokenizer, target_tokenizer, source_vocab, target_vocab):\n",
    "        \"\"\"\n",
    "        初始化数据集。\n",
    "        source_sentences: 源语言句子列表。\n",
    "        target_sentences: 目标语言句子列表。\n",
    "        source_tokenizer: 源语言分词函数。\n",
    "        target_tokenizer: 目标语言分词函数。\n",
    "        source_vocab: 源语言词汇表。\n",
    "        target_vocab: 目标语言词汇表。\n",
    "        \"\"\"\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.source_tokenizer = source_tokenizer\n",
    "        self.target_tokenizer = target_tokenizer\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        # 确保源语言和目标语言数据列表的长度相等\n",
    "        assert len(self.source_sentences) == len(self.target_sentences)\n",
    "        # 返回数据集的大小\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 获取单个句子\n",
    "        source_sentence = self.source_sentences[index]\n",
    "        target_sentence = self.target_sentences[index]\n",
    "        \n",
    "        # 对句子分词\n",
    "        source_words = self.source_tokenizer(source_sentence)\n",
    "        target_words = self.target_tokenizer(target_sentence)\n",
    "\n",
    "        # 将分词结果转换为索引（如果词不在词汇表中，将使用 <unk> 的索引号）\n",
    "        source_indices = [self.source_vocab.get(word, self.source_vocab['<unk>']) for word in source_words]\n",
    "        target_indices = [self.target_vocab.get(word, self.target_vocab['<unk>']) for word in target_words]\n",
    "\n",
    "        # 在序列的开始和结束分别添加特殊标记<sos>和<eos>\n",
    "        source_indices = [self.source_vocab['<sos>']] + source_indices + [self.source_vocab['<eos>']]\n",
    "        target_indices = [self.target_vocab['<sos>']] + target_indices + [self.target_vocab['<eos>']]\n",
    "\n",
    "        # 将索引列表转换为PyTorch张量\n",
    "        src_tensor = torch.tensor(source_indices, dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "\n",
    "        return src_tensor, tgt_tensor\n",
    "\n",
    "    # 自定义批处理函数，用于数据加载器在加载批次数据时的数据处理\n",
    "    def collate_fn(self, batch):\n",
    "        # 将批次中的数据分解为源语言和目标语言张量列表\n",
    "        src_tensors, tgt_tensors = zip(*batch)  # zip(*batch)：功能是将batch中一个个元组(src_tensor, tgt_tensor)先拆开，然后把所有src_tensor们组织到一起，把tgt_tensor们也组织到一起。\n",
    "        # 使用pad_sequence对序列进行填充，使得批次中的所有序列长度相等，填充值为<pad>标记的索引\n",
    "        src_tensors = torch.nn.utils.rnn.pad_sequence(src_tensors, padding_value=self.source_vocab['<pad>'], batch_first=True) # 当batch_first=True时，输出张量的形状将为 (batch_size, sequence_length, *)。如果不加，默认是False，输出维度为：(sequence_length, batch_size, *)\n",
    "        tgt_tensors = torch.nn.utils.rnn.pad_sequence(tgt_tensors, padding_value=self.target_vocab['<pad>'], batch_first=True)\n",
    "\n",
    "        # 返回处理好的源语言和目标语言批次数据\n",
    "        return src_tensors, tgt_tensors\n",
    "\n",
    "\n",
    "\n",
    "# 中文分词器\n",
    "def tokenize_zh(text):\n",
    "    \"\"\"使用jieba分词来分割中文句子\"\"\"\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# 英文分词器\n",
    "def tokenize_en(text):\n",
    "    return text.split() # 直接通过空格分隔句子\n",
    "\n",
    "\n",
    "# 构建词汇表的函数\n",
    "def build_tokenizer(lang_data, language='English'):\n",
    "    # 初始化词汇表：pad代表空白填充、sos是开始标记、eos是结束标记、unk表示未知标记（主要用于没在训练集词汇表中出现过的词）\n",
    "    word_to_index = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3} \n",
    "    index = 4  # 从4开始编号，因为0-3已被特殊字符占用\n",
    "    for sentence in lang_data:\n",
    "        # 根据语言选择分词方法\n",
    "        if language == 'Chinese':\n",
    "            words = tokenize_zh(sentence)\n",
    "        else:\n",
    "            words = tokenize_en(sentence)\n",
    "            \n",
    "        for word in words:\n",
    "            if word not in word_to_index:\n",
    "                word_to_index[word] = index\n",
    "                index += 1\n",
    "    return word_to_index\n",
    "\n",
    "\n",
    "# 从文件中读取数据\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.read().strip().split('\\n')\n",
    "    source_data = [line.split('\\t')[0] for line in lines]\n",
    "    target_data = [line.split('\\t')[1] for line in lines]\n",
    "    return source_data, target_data\n",
    "\n",
    "\n",
    "\n",
    "# 从文件中加载英文和中文数据\n",
    "train_data_en, train_data_zh = read_data(train_path)\n",
    "val_data_en, val_data_zh = read_data(val_path)\n",
    "test_data_en, test_data_zh = read_data(test_path)\n",
    "\n",
    "# 创建英文和中文的词汇表\n",
    "EN_VOCAB  = build_tokenizer(train_data_en, language='English')\n",
    "ZH_VOCAB = build_tokenizer(train_data_zh, language='Chinese')\n",
    "# 创建 index-to-word 字典\n",
    "INDEX_TO_EN_VOCAB = {index: word for word, index in EN_VOCAB.items()}\n",
    "# 创建 index-to-word 字典\n",
    "INDEX_TO_ZH_VOCAB = {index: word for word, index in ZH_VOCAB.items()}\n",
    "\n",
    "\n",
    "# 创建数据集实例\n",
    "train_dataset = TranslationDataset(train_data_en, train_data_zh, tokenize_en, tokenize_zh, EN_VOCAB, ZH_VOCAB)\n",
    "val_dataset = TranslationDataset(val_data_en, val_data_zh, tokenize_en, tokenize_zh, EN_VOCAB, ZH_VOCAB)\n",
    "test_dataset = TranslationDataset(test_data_en, test_data_zh, tokenize_en, tokenize_zh, EN_VOCAB, ZH_VOCAB)\n",
    "\n",
    "# 创建DataLoader对象\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=val_dataset.collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文本: i will write to you soon . \n",
      "目标文本: 我会尽快写信给你。\n",
      "分词后的原文本: ['i', 'will', 'write', 'to', 'you', 'soon', '.']\n",
      "分词后的目标文本: ['我会', '尽快', '写信给', '你', '。']\n",
      "英文词汇表个数: 5581\n",
      "英文词汇表样本: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('it', 4), (\"'s\", 5), ('none', 6), ('of', 7), ('your', 8), ('concern', 9)]\n",
      "中文词汇表个数: 9120\n",
      "中文词汇表样本: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('这不关', 4), ('你', 5), ('的', 6), ('事', 7), ('。', 8), ('她', 9)]\n"
     ]
    }
   ],
   "source": [
    "# 打印原文本和目标文本\n",
    "sample_source_text = train_data_en[280]\n",
    "sample_target_text = train_data_zh[280]\n",
    "print(\"原文本:\", sample_source_text)\n",
    "print(\"目标文本:\", sample_target_text)\n",
    "\n",
    "# 打印分词后的原文本和目标文本\n",
    "print(\"分词后的原文本:\", tokenize_en(sample_source_text))\n",
    "print(\"分词后的目标文本:\", tokenize_zh(sample_target_text))\n",
    "\n",
    "# 显示英文词汇表的一部分\n",
    "print(\"英文词汇表个数:\", len(EN_VOCAB))\n",
    "print(\"英文词汇表样本:\", list(EN_VOCAB.items())[:10])\n",
    "# 显示中文词汇表的一部分\n",
    "print(\"中文词汇表个数:\", len(ZH_VOCAB))\n",
    "print(\"中文词汇表样本:\", list(ZH_VOCAB.items())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PositionalEncoding类继承自nn.Module，是一个PyTorch模块\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    # 类的初始化方法\n",
    "    def __init__(self, d_model, max_seq_len, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化PositionalEncoding模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入向量的维度。\n",
    "        max_seq_len (int): 输入序列的最大长度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        # 调用父类的初始化方法\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 定义一个dropout层，用于在位置编码加到输入向量之后进行dropout操作\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 初始化一个位置编码矩阵，全为零，形状为(max_seq_len, d_model)\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # 生成一个位置索引向量，形状为(max_seq_len, 1)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # 生成除数项，用于计算正弦和余弦函数的参数，形状为(d_model / 2,)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        # 计算位置编码的正弦部分，填充到偶数位置\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算位置编码的余弦部分，填充到奇数位置\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 增加一个维度，使pe的形状为(1, max_seq_len, d_model)，方便后续的广播操作\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 将位置编码矩阵注册为一个buffer，这样它就可以被保存在模型的state_dict中了，\n",
    "        # 虽然它不是一个可学习的参数。\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    # 定义前向传播方法\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        PositionalEncoding的前向传播方法。\n",
    "        \n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 将位置编码加到输入张量上，使用广播机制匹配序列长度\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        # 对加上位置编码后的输入进行dropout操作\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 返回处理后的张量\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# AddNorm类继承自nn.Module，是PyTorch中的标准写法\n",
    "class AddNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        \"\"\"\n",
    "        初始化AddNorm模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        eps (float, optional): 为了数值稳定性而加入的一个小常数，默认值为1e-6。\n",
    "        \"\"\"\n",
    "        super(AddNorm, self).__init__()  # 调用父类的初始化函数\n",
    "        # 初始化一个层归一化（LayerNorm）模块，它会对输入张量的最后一维进行归一化\n",
    "        self.norm = nn.LayerNorm(d_model, eps=eps)\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        \"\"\"\n",
    "        AddNorm的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "        residual (Tensor): 残差张量，与输入张量形状相同。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状也为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 首先进行残差连接，即将输入张量和残差张量相加\n",
    "        out = x + residual\n",
    "        # 然后对相加后的结果进行层归一化处理\n",
    "        out = self.norm(out)\n",
    "\n",
    "        # 返回归一化后的输出张量\n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# 定义多头自注意力模块，继承自nn.Module\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"\n",
    "        初始化多头自注意力模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        num_heads (int): 注意力头的数量。\n",
    "        \"\"\"\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model  # 保存输入维度\n",
    "        self.num_heads = num_heads  # 保存头的数量\n",
    "        self.head_dim = d_model // num_heads  # 计算每个头的维度\n",
    "\n",
    "        # 确保d_model能被num_heads整除，保证等分\n",
    "        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        # 定义全连接层，用于生成查询、键、值\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 定义输出全连接层\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        多头自注意力的前向传播。\n",
    "\n",
    "        参数:\n",
    "        q (Tensor): 查询张量，形状为(batch_size, seq_length, d_model)。\n",
    "        k (Tensor): 键张量，形状为(batch_size, seq_length, d_model)。\n",
    "        v (Tensor): 值张量，形状为(batch_size, seq_length, d_model)。\n",
    "        mask (Tensor, optional): 掩码张量，用于忽略某些元素，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # 将查询、键、值通过全连接层后，改变形状以适应多头处理\n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "\n",
    "        # 转置操作，以满足矩阵乘法的需求\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        # 计算注意力权重矩阵\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # 如果提供了掩码，则应用掩码\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # 应用softmax获取标准化的注意力权重\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        # 根据注意力权重计算输出值\n",
    "        out = torch.matmul(attn, v).transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        # 将输出通过最后一个全连接层\n",
    "        out = self.wo(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "# PositionwiseFeedForward类继承自nn.Module，是一个PyTorch模块\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化逐位置前馈网络模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        d_ff (int): 前馈网络隐藏层的维度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        # 定义第一个全连接层，将输入维度从d_model映射到d_ff\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        # 定义一个dropout层，用于防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 定义第二个全连接层，将维度从d_ff映射回d_model\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        逐位置前馈网络的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 通过第一个全连接层\n",
    "        out = self.linear1(x)\n",
    "        # 应用ReLU激活函数\n",
    "        out = F.relu(out)\n",
    "        # 应用dropout\n",
    "        out = self.dropout(out)\n",
    "        # 通过第二个全连接层\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # 返回最终的输出张量\n",
    "        return out\n",
    "\n",
    "\n",
    "# EncoderBlock类继承自nn.Module，是一个PyTorch模块\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化编码器块模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        num_heads (int): 注意力机制中头的数量。\n",
    "        d_ff (int): 前馈网络中隐藏层的维度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        # 初始化多头自注意力层\n",
    "        self.self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        # 初始化第一个添加残差连接和层归一化的模块\n",
    "        self.norm1 = AddNorm(d_model)\n",
    "        # 初始化逐位置前馈网络\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        # 初始化第二个添加残差连接和层归一化的模块\n",
    "        self.norm2 = AddNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        编码器块的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。seq_length取当前批次最长句子的长度值。\n",
    "        mask (Tensor, optional): 掩码张量，用于忽略某些元素，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 通过多头自注意力层处理输入\n",
    "        x1 = self.self_attn(q=x, k=x, v=x, mask=mask)\n",
    "        # 应用残差连接和层归一化\n",
    "        x = self.norm1(x, x1)\n",
    "        # 通过逐位置前馈网络处理\n",
    "        x1 = self.ffn(x)\n",
    "        # 再次应用残差连接和层归一化\n",
    "        x = self.norm2(x, x1)\n",
    "\n",
    "        # 返回最终的输出\n",
    "        return x\n",
    "\n",
    "\n",
    "# DecoderBlock类继承自nn.Module，是一个PyTorch模块\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化解码器块模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        num_heads (int): 注意力机制中头的数量。\n",
    "        d_ff (int): 前馈网络中隐藏层的维度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # 初始化自注意力层\n",
    "        self.self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        # 初始化第一个残差连接和层归一化\n",
    "        self.norm1 = AddNorm(d_model)\n",
    "        # 初始化编码器-解码器注意力层，用于关注编码器的输出\n",
    "        self.enc_dec_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        # 初始化第二个残差连接和层归一化\n",
    "        self.norm2 = AddNorm(d_model)\n",
    "        # 初始化逐位置前馈网络\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        # 初始化第三个残差连接和层归一化\n",
    "        self.norm3 = AddNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        解码器块的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 目标输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "        enc_output (Tensor): 编码器输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        src_mask (Tensor, optional): 来源掩码张量，用于忽略某些元素，针对编码器输出，默认为None。\n",
    "        tgt_mask (Tensor, optional): 目标掩码张量，用于忽略某些元素，针对自注意力层，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 通过自注意力层处理输入\n",
    "        x1 = self.self_attn(q=x, k=x, v=x, mask=tgt_mask)\n",
    "        # 应用残差连接和层归一化\n",
    "        x = self.norm1(x, x1)\n",
    "        # 通过编码器-解码器注意力层处理，关注编码器的输出\n",
    "        x1 = self.enc_dec_attn(q=x, k=enc_output, v=enc_output, mask=src_mask)\n",
    "        # 再次应用残差连接和层归一化\n",
    "        x = self.norm2(x, x1)\n",
    "        # 通过逐位置前馈网络处理\n",
    "        x1 = self.ffn(x)\n",
    "        # 最后再次应用残差连接和层归一化\n",
    "        x = self.norm3(x, x1)\n",
    "\n",
    "        # 返回最终的输出\n",
    "        return x\n",
    "\n",
    "\n",
    "# Transformer类继承自nn.Module，是一个PyTorch模块\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, D_MODEL, num_heads, d_ff, max_seq_len, num_layers, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化Transformer模块。\n",
    "\n",
    "        参数:\n",
    "        src_vocab_size (int): 源词汇表的大小。\n",
    "        tgt_vocab_size (int): 目标词汇表的大小。\n",
    "        D_MODEL (int): 嵌入向量的维度。\n",
    "        num_heads (int): 注意力机制中头的数量。\n",
    "        d_ff (int): 前馈网络中隐藏层的维度。\n",
    "        max_seq_len (int): 输入序列的最大长度。\n",
    "        num_layers (int): 编码器和解码器中层的数量。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        # 初始化源词嵌入层\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, D_MODEL)\n",
    "        # 初始化目标词嵌入层\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, D_MODEL)\n",
    "        # 初始化位置编码\n",
    "        self.pos_encoding = PositionalEncoding(D_MODEL, max_seq_len, dropout)\n",
    "\n",
    "        # 初始化编码器层，使用ModuleList容纳多个EncoderBlock实例\n",
    "        self.encoder_layers = nn.ModuleList([EncoderBlock(D_MODEL, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        # 初始化解码器层，同样使用ModuleList\n",
    "        self.decoder_layers = nn.ModuleList([DecoderBlock(D_MODEL, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        # 初始化一个全连接层，用于将解码器的输出映射到目标词汇空间\n",
    "        self.fc = nn.Linear(D_MODEL, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        Transformer的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        src (Tensor): 源输入张量，形状为(batch_size, src_seq_length)。src_seq_length取当前批次中长度最大的那个句子长度。\n",
    "        tgt (Tensor): 目标输入张量，形状为(batch_size, tgt_seq_length)。\n",
    "        src_mask (Tensor, optional): 源掩码张量，用于忽略某些元素，默认为None。\n",
    "        tgt_mask (Tensor, optional): 目标掩码张量，用于忽略某些元素，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, tgt_seq_length, tgt_vocab_size)。\n",
    "        \"\"\"\n",
    "        # 对源序列进行词嵌入和位置编码\n",
    "        src = self.src_embedding(src) #[batch_size, src_seq_length]->[bs, s_s_l, d_model]\n",
    "        src = self.pos_encoding(src)\n",
    "\n",
    "        # 对目标序列进行词嵌入和位置编码\n",
    "        tgt = self.tgt_embedding(tgt)\n",
    "        tgt = self.pos_encoding(tgt)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #测试对解码器的输入tgt进行mask，防止残差泄露信息\n",
    "        # 调整掩码形状\n",
    "        #tgt = tgt.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "\n",
    "        # 依次通过编码器层\n",
    "        for layer in self.encoder_layers:\n",
    "            src = layer(src, src_mask)\n",
    "\n",
    "        # 依次通过解码器层，需要提供编码器的输出和掩码信息\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt = layer(tgt, src, src_mask, tgt_mask)\n",
    "\n",
    "        # 通过最后的全连接层，映射到目标词汇空间\n",
    "        out = self.fc(tgt)\n",
    "\n",
    "        return out    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================\n",
      "                                           Kernel Shape     Output Shape  \\\n",
      "Layer                                                                      \n",
      "0_src_embedding                             [256, 5581]   [128, 19, 256]   \n",
      "1_pos_encoding.Dropout_dropout                        -   [128, 19, 256]   \n",
      "2_tgt_embedding                             [256, 9120]   [128, 15, 256]   \n",
      "3_pos_encoding.Dropout_dropout                        -   [128, 15, 256]   \n",
      "4_encoder_layers.0.self_attn.Linear_wq       [256, 256]   [128, 19, 256]   \n",
      "5_encoder_layers.0.self_attn.Linear_wk       [256, 256]   [128, 19, 256]   \n",
      "6_encoder_layers.0.self_attn.Linear_wv       [256, 256]   [128, 19, 256]   \n",
      "7_encoder_layers.0.self_attn.Linear_wo       [256, 256]   [128, 19, 256]   \n",
      "8_encoder_layers.0.norm1.LayerNorm_norm           [256]   [128, 19, 256]   \n",
      "9_encoder_layers.0.ffn.Linear_linear1        [256, 512]   [128, 19, 512]   \n",
      "10_encoder_layers.0.ffn.Dropout_dropout               -   [128, 19, 512]   \n",
      "11_encoder_layers.0.ffn.Linear_linear2       [512, 256]   [128, 19, 256]   \n",
      "12_encoder_layers.0.norm2.LayerNorm_norm          [256]   [128, 19, 256]   \n",
      "13_encoder_layers.1.self_attn.Linear_wq      [256, 256]   [128, 19, 256]   \n",
      "14_encoder_layers.1.self_attn.Linear_wk      [256, 256]   [128, 19, 256]   \n",
      "15_encoder_layers.1.self_attn.Linear_wv      [256, 256]   [128, 19, 256]   \n",
      "16_encoder_layers.1.self_attn.Linear_wo      [256, 256]   [128, 19, 256]   \n",
      "17_encoder_layers.1.norm1.LayerNorm_norm          [256]   [128, 19, 256]   \n",
      "18_encoder_layers.1.ffn.Linear_linear1       [256, 512]   [128, 19, 512]   \n",
      "19_encoder_layers.1.ffn.Dropout_dropout               -   [128, 19, 512]   \n",
      "20_encoder_layers.1.ffn.Linear_linear2       [512, 256]   [128, 19, 256]   \n",
      "21_encoder_layers.1.norm2.LayerNorm_norm          [256]   [128, 19, 256]   \n",
      "22_encoder_layers.2.self_attn.Linear_wq      [256, 256]   [128, 19, 256]   \n",
      "23_encoder_layers.2.self_attn.Linear_wk      [256, 256]   [128, 19, 256]   \n",
      "24_encoder_layers.2.self_attn.Linear_wv      [256, 256]   [128, 19, 256]   \n",
      "25_encoder_layers.2.self_attn.Linear_wo      [256, 256]   [128, 19, 256]   \n",
      "26_encoder_layers.2.norm1.LayerNorm_norm          [256]   [128, 19, 256]   \n",
      "27_encoder_layers.2.ffn.Linear_linear1       [256, 512]   [128, 19, 512]   \n",
      "28_encoder_layers.2.ffn.Dropout_dropout               -   [128, 19, 512]   \n",
      "29_encoder_layers.2.ffn.Linear_linear2       [512, 256]   [128, 19, 256]   \n",
      "30_encoder_layers.2.norm2.LayerNorm_norm          [256]   [128, 19, 256]   \n",
      "31_decoder_layers.0.self_attn.Linear_wq      [256, 256]   [128, 15, 256]   \n",
      "32_decoder_layers.0.self_attn.Linear_wk      [256, 256]   [128, 15, 256]   \n",
      "33_decoder_layers.0.self_attn.Linear_wv      [256, 256]   [128, 15, 256]   \n",
      "34_decoder_layers.0.self_attn.Linear_wo      [256, 256]   [128, 15, 256]   \n",
      "35_decoder_layers.0.norm1.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "36_decoder_layers.0.enc_dec_attn.Linear_wq   [256, 256]   [128, 15, 256]   \n",
      "37_decoder_layers.0.enc_dec_attn.Linear_wk   [256, 256]   [128, 19, 256]   \n",
      "38_decoder_layers.0.enc_dec_attn.Linear_wv   [256, 256]   [128, 19, 256]   \n",
      "39_decoder_layers.0.enc_dec_attn.Linear_wo   [256, 256]   [128, 15, 256]   \n",
      "40_decoder_layers.0.norm2.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "41_decoder_layers.0.ffn.Linear_linear1       [256, 512]   [128, 15, 512]   \n",
      "42_decoder_layers.0.ffn.Dropout_dropout               -   [128, 15, 512]   \n",
      "43_decoder_layers.0.ffn.Linear_linear2       [512, 256]   [128, 15, 256]   \n",
      "44_decoder_layers.0.norm3.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "45_decoder_layers.1.self_attn.Linear_wq      [256, 256]   [128, 15, 256]   \n",
      "46_decoder_layers.1.self_attn.Linear_wk      [256, 256]   [128, 15, 256]   \n",
      "47_decoder_layers.1.self_attn.Linear_wv      [256, 256]   [128, 15, 256]   \n",
      "48_decoder_layers.1.self_attn.Linear_wo      [256, 256]   [128, 15, 256]   \n",
      "49_decoder_layers.1.norm1.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "50_decoder_layers.1.enc_dec_attn.Linear_wq   [256, 256]   [128, 15, 256]   \n",
      "51_decoder_layers.1.enc_dec_attn.Linear_wk   [256, 256]   [128, 19, 256]   \n",
      "52_decoder_layers.1.enc_dec_attn.Linear_wv   [256, 256]   [128, 19, 256]   \n",
      "53_decoder_layers.1.enc_dec_attn.Linear_wo   [256, 256]   [128, 15, 256]   \n",
      "54_decoder_layers.1.norm2.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "55_decoder_layers.1.ffn.Linear_linear1       [256, 512]   [128, 15, 512]   \n",
      "56_decoder_layers.1.ffn.Dropout_dropout               -   [128, 15, 512]   \n",
      "57_decoder_layers.1.ffn.Linear_linear2       [512, 256]   [128, 15, 256]   \n",
      "58_decoder_layers.1.norm3.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "59_decoder_layers.2.self_attn.Linear_wq      [256, 256]   [128, 15, 256]   \n",
      "60_decoder_layers.2.self_attn.Linear_wk      [256, 256]   [128, 15, 256]   \n",
      "61_decoder_layers.2.self_attn.Linear_wv      [256, 256]   [128, 15, 256]   \n",
      "62_decoder_layers.2.self_attn.Linear_wo      [256, 256]   [128, 15, 256]   \n",
      "63_decoder_layers.2.norm1.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "64_decoder_layers.2.enc_dec_attn.Linear_wq   [256, 256]   [128, 15, 256]   \n",
      "65_decoder_layers.2.enc_dec_attn.Linear_wk   [256, 256]   [128, 19, 256]   \n",
      "66_decoder_layers.2.enc_dec_attn.Linear_wv   [256, 256]   [128, 19, 256]   \n",
      "67_decoder_layers.2.enc_dec_attn.Linear_wo   [256, 256]   [128, 15, 256]   \n",
      "68_decoder_layers.2.norm2.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "69_decoder_layers.2.ffn.Linear_linear1       [256, 512]   [128, 15, 512]   \n",
      "70_decoder_layers.2.ffn.Dropout_dropout               -   [128, 15, 512]   \n",
      "71_decoder_layers.2.ffn.Linear_linear2       [512, 256]   [128, 15, 256]   \n",
      "72_decoder_layers.2.norm3.LayerNorm_norm          [256]   [128, 15, 256]   \n",
      "73_fc                                       [256, 9120]  [128, 15, 9120]   \n",
      "\n",
      "                                               Params  Mult-Adds  \n",
      "Layer                                                             \n",
      "0_src_embedding                             1.428736M  1.428736M  \n",
      "1_pos_encoding.Dropout_dropout                      -          -  \n",
      "2_tgt_embedding                              2.33472M   2.33472M  \n",
      "3_pos_encoding.Dropout_dropout                      -          -  \n",
      "4_encoder_layers.0.self_attn.Linear_wq        65.792k    65.536k  \n",
      "5_encoder_layers.0.self_attn.Linear_wk        65.792k    65.536k  \n",
      "6_encoder_layers.0.self_attn.Linear_wv        65.792k    65.536k  \n",
      "7_encoder_layers.0.self_attn.Linear_wo        65.792k    65.536k  \n",
      "8_encoder_layers.0.norm1.LayerNorm_norm         512.0      256.0  \n",
      "9_encoder_layers.0.ffn.Linear_linear1        131.584k   131.072k  \n",
      "10_encoder_layers.0.ffn.Dropout_dropout             -          -  \n",
      "11_encoder_layers.0.ffn.Linear_linear2       131.328k   131.072k  \n",
      "12_encoder_layers.0.norm2.LayerNorm_norm        512.0      256.0  \n",
      "13_encoder_layers.1.self_attn.Linear_wq       65.792k    65.536k  \n",
      "14_encoder_layers.1.self_attn.Linear_wk       65.792k    65.536k  \n",
      "15_encoder_layers.1.self_attn.Linear_wv       65.792k    65.536k  \n",
      "16_encoder_layers.1.self_attn.Linear_wo       65.792k    65.536k  \n",
      "17_encoder_layers.1.norm1.LayerNorm_norm        512.0      256.0  \n",
      "18_encoder_layers.1.ffn.Linear_linear1       131.584k   131.072k  \n",
      "19_encoder_layers.1.ffn.Dropout_dropout             -          -  \n",
      "20_encoder_layers.1.ffn.Linear_linear2       131.328k   131.072k  \n",
      "21_encoder_layers.1.norm2.LayerNorm_norm        512.0      256.0  \n",
      "22_encoder_layers.2.self_attn.Linear_wq       65.792k    65.536k  \n",
      "23_encoder_layers.2.self_attn.Linear_wk       65.792k    65.536k  \n",
      "24_encoder_layers.2.self_attn.Linear_wv       65.792k    65.536k  \n",
      "25_encoder_layers.2.self_attn.Linear_wo       65.792k    65.536k  \n",
      "26_encoder_layers.2.norm1.LayerNorm_norm        512.0      256.0  \n",
      "27_encoder_layers.2.ffn.Linear_linear1       131.584k   131.072k  \n",
      "28_encoder_layers.2.ffn.Dropout_dropout             -          -  \n",
      "29_encoder_layers.2.ffn.Linear_linear2       131.328k   131.072k  \n",
      "30_encoder_layers.2.norm2.LayerNorm_norm        512.0      256.0  \n",
      "31_decoder_layers.0.self_attn.Linear_wq       65.792k    65.536k  \n",
      "32_decoder_layers.0.self_attn.Linear_wk       65.792k    65.536k  \n",
      "33_decoder_layers.0.self_attn.Linear_wv       65.792k    65.536k  \n",
      "34_decoder_layers.0.self_attn.Linear_wo       65.792k    65.536k  \n",
      "35_decoder_layers.0.norm1.LayerNorm_norm        512.0      256.0  \n",
      "36_decoder_layers.0.enc_dec_attn.Linear_wq    65.792k    65.536k  \n",
      "37_decoder_layers.0.enc_dec_attn.Linear_wk    65.792k    65.536k  \n",
      "38_decoder_layers.0.enc_dec_attn.Linear_wv    65.792k    65.536k  \n",
      "39_decoder_layers.0.enc_dec_attn.Linear_wo    65.792k    65.536k  \n",
      "40_decoder_layers.0.norm2.LayerNorm_norm        512.0      256.0  \n",
      "41_decoder_layers.0.ffn.Linear_linear1       131.584k   131.072k  \n",
      "42_decoder_layers.0.ffn.Dropout_dropout             -          -  \n",
      "43_decoder_layers.0.ffn.Linear_linear2       131.328k   131.072k  \n",
      "44_decoder_layers.0.norm3.LayerNorm_norm        512.0      256.0  \n",
      "45_decoder_layers.1.self_attn.Linear_wq       65.792k    65.536k  \n",
      "46_decoder_layers.1.self_attn.Linear_wk       65.792k    65.536k  \n",
      "47_decoder_layers.1.self_attn.Linear_wv       65.792k    65.536k  \n",
      "48_decoder_layers.1.self_attn.Linear_wo       65.792k    65.536k  \n",
      "49_decoder_layers.1.norm1.LayerNorm_norm        512.0      256.0  \n",
      "50_decoder_layers.1.enc_dec_attn.Linear_wq    65.792k    65.536k  \n",
      "51_decoder_layers.1.enc_dec_attn.Linear_wk    65.792k    65.536k  \n",
      "52_decoder_layers.1.enc_dec_attn.Linear_wv    65.792k    65.536k  \n",
      "53_decoder_layers.1.enc_dec_attn.Linear_wo    65.792k    65.536k  \n",
      "54_decoder_layers.1.norm2.LayerNorm_norm        512.0      256.0  \n",
      "55_decoder_layers.1.ffn.Linear_linear1       131.584k   131.072k  \n",
      "56_decoder_layers.1.ffn.Dropout_dropout             -          -  \n",
      "57_decoder_layers.1.ffn.Linear_linear2       131.328k   131.072k  \n",
      "58_decoder_layers.1.norm3.LayerNorm_norm        512.0      256.0  \n",
      "59_decoder_layers.2.self_attn.Linear_wq       65.792k    65.536k  \n",
      "60_decoder_layers.2.self_attn.Linear_wk       65.792k    65.536k  \n",
      "61_decoder_layers.2.self_attn.Linear_wv       65.792k    65.536k  \n",
      "62_decoder_layers.2.self_attn.Linear_wo       65.792k    65.536k  \n",
      "63_decoder_layers.2.norm1.LayerNorm_norm        512.0      256.0  \n",
      "64_decoder_layers.2.enc_dec_attn.Linear_wq    65.792k    65.536k  \n",
      "65_decoder_layers.2.enc_dec_attn.Linear_wk    65.792k    65.536k  \n",
      "66_decoder_layers.2.enc_dec_attn.Linear_wv    65.792k    65.536k  \n",
      "67_decoder_layers.2.enc_dec_attn.Linear_wo    65.792k    65.536k  \n",
      "68_decoder_layers.2.norm2.LayerNorm_norm        512.0      256.0  \n",
      "69_decoder_layers.2.ffn.Linear_linear1       131.584k   131.072k  \n",
      "70_decoder_layers.2.ffn.Dropout_dropout             -          -  \n",
      "71_decoder_layers.2.ffn.Linear_linear2       131.328k   131.072k  \n",
      "72_decoder_layers.2.norm3.LayerNorm_norm        512.0      256.0  \n",
      "73_fc                                        2.34384M   2.33472M  \n",
      "----------------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params           10.06096M\n",
      "Trainable params       10.06096M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             10.034176M\n",
      "==============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\soft_big\\anaconda3\\envs\\torch12\\lib\\site-packages\\torchsummaryX\\torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_src_embedding</th>\n",
       "      <td>[256, 5581]</td>\n",
       "      <td>[128, 19, 256]</td>\n",
       "      <td>1428736.0</td>\n",
       "      <td>1428736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_pos_encoding.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 19, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_tgt_embedding</th>\n",
       "      <td>[256, 9120]</td>\n",
       "      <td>[128, 15, 256]</td>\n",
       "      <td>2334720.0</td>\n",
       "      <td>2334720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_pos_encoding.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 15, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_encoder_layers.0.self_attn.Linear_wq</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[128, 19, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69_decoder_layers.2.ffn.Linear_linear1</th>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>[128, 15, 512]</td>\n",
       "      <td>131584.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70_decoder_layers.2.ffn.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 15, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71_decoder_layers.2.ffn.Linear_linear2</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[128, 15, 256]</td>\n",
       "      <td>131328.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72_decoder_layers.2.norm3.LayerNorm_norm</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[128, 15, 256]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73_fc</th>\n",
       "      <td>[256, 9120]</td>\n",
       "      <td>[128, 15, 9120]</td>\n",
       "      <td>2343840.0</td>\n",
       "      <td>2334720.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Kernel Shape     Output Shape  \\\n",
       "Layer                                                                    \n",
       "0_src_embedding                           [256, 5581]   [128, 19, 256]   \n",
       "1_pos_encoding.Dropout_dropout                      -   [128, 19, 256]   \n",
       "2_tgt_embedding                           [256, 9120]   [128, 15, 256]   \n",
       "3_pos_encoding.Dropout_dropout                      -   [128, 15, 256]   \n",
       "4_encoder_layers.0.self_attn.Linear_wq     [256, 256]   [128, 19, 256]   \n",
       "...                                               ...              ...   \n",
       "69_decoder_layers.2.ffn.Linear_linear1     [256, 512]   [128, 15, 512]   \n",
       "70_decoder_layers.2.ffn.Dropout_dropout             -   [128, 15, 512]   \n",
       "71_decoder_layers.2.ffn.Linear_linear2     [512, 256]   [128, 15, 256]   \n",
       "72_decoder_layers.2.norm3.LayerNorm_norm        [256]   [128, 15, 256]   \n",
       "73_fc                                     [256, 9120]  [128, 15, 9120]   \n",
       "\n",
       "                                             Params  Mult-Adds  \n",
       "Layer                                                           \n",
       "0_src_embedding                           1428736.0  1428736.0  \n",
       "1_pos_encoding.Dropout_dropout                  NaN        NaN  \n",
       "2_tgt_embedding                           2334720.0  2334720.0  \n",
       "3_pos_encoding.Dropout_dropout                  NaN        NaN  \n",
       "4_encoder_layers.0.self_attn.Linear_wq      65792.0    65536.0  \n",
       "...                                             ...        ...  \n",
       "69_decoder_layers.2.ffn.Linear_linear1     131584.0   131072.0  \n",
       "70_decoder_layers.2.ffn.Dropout_dropout         NaN        NaN  \n",
       "71_decoder_layers.2.ffn.Linear_linear2     131328.0   131072.0  \n",
       "72_decoder_layers.2.norm3.LayerNorm_norm      512.0      256.0  \n",
       "73_fc                                     2343840.0  2334720.0  \n",
       "\n",
       "[74 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义训练时的超参数\n",
    "NUM_EPOCHS      = 10            # 训练的轮数\n",
    "D_MODEL         = 256           # 模型中嵌入向量的维度\n",
    "ATTN_HEADS      = 8             # 多头注意力中头的数量\n",
    "NUM_LAYERS      = 3             # 编码器和解码器层重复的次数\n",
    "FEEDFORWARD_DIM = 512           # 前馈网络中隐藏层的维度\n",
    "DROPOUT         = 0.1           # Dropout概率，用于防止过拟合\n",
    "MAX_SEQ_LEN     = 150           # 输入序列的最大长度\n",
    "SRC_VOCAB_SIZE  = len(EN_VOCAB)  # 源语言词汇表的大小\n",
    "TGT_VOCAB_SIZE  = len(ZH_VOCAB)  # 目标语言词汇表的大小\n",
    "LR              = 0             # 学习率，这里设置为0可能是为了后续调整\n",
    "\n",
    "\n",
    "# 设备配置，优先使用GPU，如果没有GPU则使用CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 负责根据训练步骤动态调整学习率\n",
    "class NoamScheduler:\n",
    "\n",
    "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
    "        \"\"\"\n",
    "        初始化NoamScheduler。\n",
    "\n",
    "        参数:\n",
    "        optimizer: 用于训练的优化器。\n",
    "        d_model (int): 模型中嵌入向量的维度。\n",
    "        warmup_steps (int): 预热步数，在此步数之前学习率会线性增加。\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.current_step = 0  # 初始化当前步数\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        更新学习率并增加步数。\n",
    "        \"\"\"\n",
    "        self.current_step += 1  # 每调用一次，步数增加1\n",
    "        lr = self.learning_rate()  # 计算当前步数的学习率\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr  # 更新优化器中的学习率\n",
    "\n",
    "    def learning_rate(self):\n",
    "        \"\"\"\n",
    "        根据当前步数计算学习率。\n",
    "        \"\"\"\n",
    "        step = self.current_step\n",
    "        # 学习率随着步数先增后减，增加部分线性增加至warmup_steps，之后随步数的增加而减小\n",
    "        return (self.d_model ** -0.5) * min(step ** -0.5, step * self.warmup_steps ** -1.5)\n",
    "\n",
    "\n",
    "# 初始化Transformer模型，并将其移动到适当的设备上\n",
    "model = Transformer(SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, D_MODEL, ATTN_HEADS, FEEDFORWARD_DIM, MAX_SEQ_LEN, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
    "\n",
    "# 初始化优化器，这里使用AdamW优化器，它是Adam优化器的一个变种，添加了权重衰减\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9, weight_decay=5e-2)\n",
    "\n",
    "# 根据训练数据加载器的长度计算预热步数\n",
    "warmup_steps = 2 * len(train_dataloader)\n",
    "\n",
    "# 使用NoamScheduler作为学习率调度器\n",
    "scheduler = NoamScheduler(optimizer, d_model=D_MODEL, warmup_steps=warmup_steps)\n",
    "\n",
    "# 初始化损失函数，使用交叉熵损失，并忽略'<pad>'标记的损失，同时应用标签平滑\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=ZH_VOCAB['<pad>'], label_smoothing=0.1)\n",
    "\n",
    "# 初始化梯度缩放器，用于混合精度训练，有助于提高训练速度和减少内存消耗\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "import sacrebleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "def generate_tgt_mask(tgt, pad_idx):\n",
    "    \"\"\"\n",
    "    生成目标序列的掩码，遮蔽未来位置以及填充位置。\n",
    "    \n",
    "    参数:\n",
    "    tgt (Tensor): 目标序列。\n",
    "    pad_idx (int): `<pad>`标记的索引。\n",
    "    \n",
    "    返回:\n",
    "    Tensor: 组合掩码。\n",
    "    \"\"\"\n",
    "    seq_len = tgt.size(1)\n",
    "    # 生成一个下三角矩阵，用于屏蔽未来的信息\n",
    "    no_future_mask = torch.tril(torch.ones((seq_len, seq_len), device=DEVICE)).bool()\n",
    "    # 生成一个填充位置的掩码\n",
    "    pad_mask = (tgt != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    # 将两个掩码相与，得到最终的掩码\n",
    "    combined_mask = pad_mask & no_future_mask\n",
    "    return combined_mask\n",
    "\n",
    "\n",
    "def generate_src_mask(src, pad_idx):\n",
    "    \"\"\"\n",
    "    生成源序列的掩码，遮蔽填充位置。\n",
    "    \n",
    "    参数:\n",
    "    src (Tensor): 源序列。\n",
    "    pad_idx (int): `<pad>`标记的索引。\n",
    "    \n",
    "    返回:\n",
    "    Tensor: 源序列的掩码。\n",
    "    \"\"\"\n",
    "    mask = (src != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def calculate_bleu(tgt_output, output):\n",
    "    \"\"\"\n",
    "    计算BLEU分数。\n",
    "    \n",
    "    参数:\n",
    "    tgt_output (Tensor): 真实的目标序列。维度：[batchsize, 句子最大长度]\n",
    "    output (Tensor): 模型生成的输出序列。维度：[batchsize, 句子最大长度]\n",
    "    \n",
    "    返回:\n",
    "    float: BLEU分数。\n",
    "    \"\"\"\n",
    "    tgt_output = tgt_output.cpu().numpy()\n",
    "    output = output.cpu().numpy()\n",
    "\n",
    "    bleu = 0\n",
    "    \n",
    "    # 需要排除的标记\n",
    "    excluded_tokens = (ZH_VOCAB['<pad>'], ZH_VOCAB['<eos>'], ZH_VOCAB['<sos>'])\n",
    "    for tgt, pred in zip(tgt_output, output):\n",
    "        # 将索引转换为单词，排除特定标记\n",
    "        ref = ' '.join([INDEX_TO_ZH_VOCAB.get(t, '<unk>') for t in tgt if t not in excluded_tokens])\n",
    "        hyp = ' '.join([INDEX_TO_ZH_VOCAB.get(t, '<unk>') for t in pred if t not in excluded_tokens])\n",
    "        \n",
    "        bleu += sacrebleu.corpus_bleu([hyp], [[ref]]).score\n",
    "\n",
    "    # 平均BLEU分数（批放进去，数据结果有点难懂，所以用单个句子放进去求平均）\n",
    "    return bleu/len(tgt_output)\n",
    "\n",
    "\n",
    "src, tgt = next(iter(train_dataloader))\n",
    "src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "\n",
    "src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])\n",
    "\n",
    "tgt_input = tgt[:, :-1]\n",
    "tgt_output = tgt[:, 1:]\n",
    "tgt_mask = generate_tgt_mask(tgt_input, ZH_VOCAB['<pad>'])\n",
    "\n",
    "summary(model, src, tgt_input, src_mask, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.7974 | Val Loss: 4.6357 | BLEU Score: 3.9801\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.2748 | Val Loss: 4.0811 | BLEU Score: 5.3245\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6974 | Val Loss: 3.7223 | BLEU Score: 6.7606\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.1673 | Val Loss: 3.5713 | BLEU Score: 7.3285\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7599 | Val Loss: 3.4431 | BLEU Score: 8.0257\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4464 | Val Loss: 3.4390 | BLEU Score: 8.2231\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2069 | Val Loss: 3.3831 | BLEU Score: 8.8944\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0361 | Val Loss: 3.3935 | BLEU Score: 9.3932\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9146 | Val Loss: 3.4245 | BLEU Score: 9.4608\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8221 | Val Loss: 3.4423 | BLEU Score: 9.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    对模型进行一个epoch的训练。\n",
    "\n",
    "    参数:\n",
    "    model: 训练的模型。\n",
    "    dataloader: 数据加载器，提供训练数据。\n",
    "    optimizer: 优化器，用于更新模型参数。\n",
    "    criterion: 损失函数。\n",
    "    device: 训练使用的设备（CPU或GPU）。\n",
    "\n",
    "    返回:\n",
    "    float: 该epoch的平均损失。\n",
    "    \"\"\"\n",
    "    model.train()  # 将模型设置为训练模式\n",
    "    total_loss = 0  # 记录总损失\n",
    "\n",
    "    # 使用tqdm库显示训练进度条\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Train')\n",
    "\n",
    "    for i, (src, tgt) in enumerate(dataloader):\n",
    "        # 将数据移动到指定的设备上\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        # 生成源序列和目标序列的掩码\n",
    "        src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])\n",
    "        tgt_input = tgt[:, :-1] #去除最末尾的sos标志\n",
    "        tgt_output = tgt[:, 1:] #去除最开始的eos标志\n",
    "        tgt_mask = generate_tgt_mask(tgt_input, ZH_VOCAB['<pad>'])\n",
    "\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "        # 使用混合精度训练\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            loss = criterion(output.reshape(-1, output.size(2)), tgt_output.reshape(-1))\n",
    "\n",
    "        # 反向传播和优化\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()  # 更新学习率\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # 更新进度条\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(total_loss / (i + 1)),\n",
    "            lr=\"{:.09f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        batch_bar.update()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, DEVICE):\n",
    "    \"\"\"\n",
    "    对模型进行一个epoch的验证。\n",
    "\n",
    "    参数:\n",
    "    model: 需要验证的模型。\n",
    "    dataloader: 数据加载器，提供验证数据。\n",
    "    criterion: 损失函数。\n",
    "    DEVICE: 验证使用的设备（CPU或GPU）。\n",
    "\n",
    "    返回:\n",
    "    tuple: 包含平均损失和平均BLEU分数的元组。\n",
    "    \"\"\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    epoch_loss = 0\n",
    "    epoch_bleu_score = 0\n",
    "\n",
    "    # 使用tqdm库显示验证进度条\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Validate')\n",
    "\n",
    "    with torch.no_grad():  # 在验证过程中不计算梯度\n",
    "        for i, (src, tgt) in enumerate(dataloader):\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            tgt_mask = generate_tgt_mask(tgt_input, ZH_VOCAB['<pad>'])\n",
    "\n",
    "            # 使用混合精度评估\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "                loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            # 计算并累加BLEU分数\n",
    "            epoch_bleu_score += calculate_bleu(tgt_output, output.argmax(-1))\n",
    "\n",
    "            # 更新进度条\n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(epoch_loss / (i + 1)),\n",
    "                bleu=\"{:.04f}\".format(epoch_bleu_score / (i + 1)))\n",
    "            batch_bar.update()\n",
    "\n",
    "    # 计算平均损失和BLEU分数\n",
    "    epoch_loss /= len(dataloader)\n",
    "    epoch_bleu_score /= len(dataloader)\n",
    "\n",
    "    return epoch_loss, epoch_bleu_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')  # 记录最佳验证损失值\n",
    "train_losses = []  # 存储每个epoch的训练损失\n",
    "val_losses = []  # 存储每个epoch的验证损失\n",
    "bleu_scores = []  # 存储每个epoch的BLEU分数\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # 训练\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, DEVICE)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # 验证\n",
    "    val_loss, bleu_score = validate_epoch(model, val_dataloader, criterion, DEVICE)\n",
    "    val_losses.append(val_loss)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "    # 如果当前验证损失低于之前的最佳值，则保存模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▍         | 1/21 [00:00<00:06,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第0句话：\n",
      "输入英语     : do n't underestimate my power .\n",
      "GT          : 不要 小看 我 的 力量 。\n",
      "模型预测     : 不要 低估 我 的 力量 。\n",
      "该句话BLEU得分：53.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 3/21 [00:00<00:03,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第128句话：\n",
      "输入英语     : do you still want to talk to me ?\n",
      "GT          : 你 还 想 跟 我 谈 吗 ？\n",
      "模型预测     : 你 还 想 跟 我 说 吗 ？\n",
      "该句话BLEU得分：59.46\n",
      "\n",
      " test集第256句话：\n",
      "输入英语     : give us a ride downtown .\n",
      "GT          : 载 我们 到 市区 。\n",
      "模型预测     : 把 一个 送 我们 去 市里 。\n",
      "该句话BLEU得分：7.81\n",
      "\n",
      " test集第384句话：\n",
      "输入英语     : my shoulder really aches .\n",
      "GT          : 我 的 肩膀 很 <unk> 。\n",
      "模型预测     : 我 的 再见 。\n",
      "该句话BLEU得分：13.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 6/21 [00:01<00:02,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第512句话：\n",
      "输入英语     : how interesting !\n",
      "GT          : 多么 有趣 啊 ！\n",
      "模型预测     : 有意思 啊 ！\n",
      "该句话BLEU得分：0.00\n",
      "\n",
      " test集第640句话：\n",
      "输入英语     : he 's used to traveling .\n",
      "GT          : 他 习惯 了 旅行 。\n",
      "模型预测     : 他 习惯 了 旅行 。\n",
      "该句话BLEU得分：100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  43%|████▎     | 9/21 [00:01<00:01,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第768句话：\n",
      "输入英语     : breakfast is from seven to nine .\n",
      "GT          : <unk> 在 七点 到 九点 。\n",
      "模型预测     : 早餐 是从 九点 到 九点 的 九点 。\n",
      "该句话BLEU得分：14.54\n",
      "\n",
      " test集第896句话：\n",
      "输入英语     : a lot of students around the world are studying english .\n",
      "GT          : 世界 上 许多 学生 正在 学习 英语 。\n",
      "模型预测     : 英语 是 世界 上 一种 全世界 通用 的 语言 。\n",
      "该句话BLEU得分：9.98\n",
      "\n",
      " test集第1024句话：\n",
      "输入英语     : japan depends on foreign countries for oil .\n",
      "GT          : 日本 依赖 外国 的 石油 。\n",
      "模型预测     : 日本 的 石油 依靠 进口 。\n",
      "该句话BLEU得分：19.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  52%|█████▏    | 11/21 [00:01<00:01,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第1152句话：\n",
      "输入英语     : i 'm bad at sports .\n",
      "GT          : 我 不 擅长 运动 。\n",
      "模型预测     : 我 不 擅长 拉 小提琴 。\n",
      "该句话BLEU得分：32.47\n",
      "\n",
      " test集第1280句话：\n",
      "输入英语     : tom studies at harvard .\n",
      "GT          : 汤姆 在 哈佛 学习 。\n",
      "模型预测     : 汤姆 在 哈佛大学 学习 。\n",
      "该句话BLEU得分：30.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  62%|██████▏   | 13/21 [00:02<00:01,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第1408句话：\n",
      "输入英语     : i walked as far as the station .\n",
      "GT          : 我们 <unk> 跟 火车站 那样 远 的 地方 。\n",
      "模型预测     : 我 走 的 走慢 一点 。\n",
      "该句话BLEU得分：4.19\n",
      "\n",
      " test集第1536句话：\n",
      "输入英语     : there is an apple on the desk .\n",
      "GT          : 书桌上 有 一个 苹果 。\n",
      "模型预测     : 桌上 有个 苹果 。\n",
      "该句话BLEU得分：24.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  71%|███████▏  | 15/21 [00:02<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第1664句话：\n",
      "输入英语     : let me die .\n",
      "GT          : 让 我 去 死 。\n",
      "模型预测     : 让 我 死 了 。\n",
      "该句话BLEU得分：25.41\n",
      "\n",
      " test集第1792句话：\n",
      "输入英语     : thank you , i 've had enough .\n",
      "GT          : 谢谢 你 ， 我 吃饱 了 。\n",
      "模型预测     : 谢谢 你 ， 我 已经 受够了 。\n",
      "该句话BLEU得分：43.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  81%|████████  | 17/21 [00:03<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第1920句话：\n",
      "输入英语     : i 'm counting on your help .\n",
      "GT          : 我 指望 你 的 帮助 。\n",
      "模型预测     : 我 在 帮忙 。\n",
      "该句话BLEU得分：11.52\n",
      "\n",
      " test集第2048句话：\n",
      "输入英语     : i used to go out with friends every weekend .\n",
      "GT          : 我 曾经 每 周末 都 和 朋友 外出 。\n",
      "模型预测     : 我 以前 上 牀 朋友 。\n",
      "该句话BLEU得分：6.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  95%|█████████▌| 20/21 [00:03<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第2176句话：\n",
      "输入英语     : we accept <unk> .\n",
      "GT          : 我们 接受 支票 。\n",
      "模型预测     : 我们 接受 了 。\n",
      "该句话BLEU得分：35.36\n",
      "\n",
      " test集第2304句话：\n",
      "输入英语     : my <unk> turned out to be right .\n",
      "GT          : 我 的 预感 被 证明 是 正确 的 。\n",
      "模型预测     : 我 的 猜想 证明 是 正确 的 。\n",
      "该句话BLEU得分：52.47\n",
      "\n",
      " test集第2432句话：\n",
      "输入英语     : may i see you in private ?\n",
      "GT          : 我们 能 私下 见见 吗 ？\n",
      "模型预测     : 我 可以 在 你 私下 吗 ？\n",
      "该句话BLEU得分：14.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 21/21 [00:03<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test集第2560句话：\n",
      "输入英语     : i 'm a stranger here myself . i 'm afraid i can not help you .\n",
      "GT          : 我 对 这里 不 熟 。 恐怕 我 不能 帮 你 。\n",
      "模型预测     : 我 害怕 这儿 的 别人 ， 我 无法 自己 一个 人 。\n",
      "该句话BLEU得分：4.46\n",
      "test集每个句子的平均 BLEU 分数: 24.267820902819505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 index-to-word 字典\n",
    "INDEX_TO_EN_VOCAB = {index: word for word, index in EN_VOCAB.items()}\n",
    "# 创建 index-to-word 字典\n",
    "INDEX_TO_ZH_VOCAB = {index: word for word, index in ZH_VOCAB.items()}\n",
    "def inference(model, src, de_tokenizer):\n",
    "    \"\"\"\n",
    "    使用训练好的模型进行推理，生成目标语言序列。\n",
    "\n",
    "    参数:\n",
    "    model: 训练好的Transformer模型。\n",
    "    src (Tensor): 源语言序列的张量。\n",
    "    de_tokenizer: 目标语言的词汇表，用于将索引转换为单词。\n",
    "\n",
    "    返回:\n",
    "    list: 生成的目标语言句子列表。\n",
    "    \"\"\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "\n",
    "    src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])  # 生成源序列的掩码\n",
    "\n",
    "    # 使用<sos>标记初始化目标输入张量\n",
    "    tgt_input = torch.full((src.size(0), 1), ZH_VOCAB['<sos>'], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # 为批处理中的每个序列创建一个结束标志\n",
    "    eos_flags = torch.zeros(src.size(0), dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "    # 对每个目标令牌进行推理\n",
    "    with torch.no_grad():\n",
    "        for _ in range(70):  # 最多生成70个令牌\n",
    "            tgt_mask = generate_tgt_mask(tgt_input, ZH_VOCAB['<pad>'])  # 生成目标序列的掩码\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            next_tokens = output.argmax(2)[:, -1].unsqueeze(1)  # 选择概率最高的下一个令牌\n",
    "            tgt_input = torch.cat((tgt_input, next_tokens), dim=1)  # 将下一个令牌添加到目标输入中\n",
    "\n",
    "            # 更新已生成<eos>标记的序列的结束标志\n",
    "            eos_flags |= (next_tokens.squeeze() == ZH_VOCAB['<eos>'])\n",
    "            # 如果所有序列都已生成<eos>或达到最大长度，则停止生成\n",
    "            if torch.all(eos_flags):\n",
    "                break\n",
    "\n",
    "    # 将目标输入张量转换为翻译后的句子\n",
    "    translated_sentences = []\n",
    "    for i in range(tgt_input.size(0)):\n",
    "        translated_tokens = []\n",
    "        for token in tgt_input[i][1:]:  # 跳过第一个<sos>标记\n",
    "            if token.item() == ZH_VOCAB['<eos>']: # 遇到<eos>标记对应的索引值时停止\n",
    "                break  \n",
    "            else:\n",
    "                translated_tokens.append(INDEX_TO_ZH_VOCAB.get(token.item(), '<unk>'))  # 将索引转换为单词, 找不到的单词置为<unk>。\n",
    "\n",
    "        translated_sentence = ' '.join(translated_tokens)  # 将单词列表连接成句子\n",
    "        translated_sentences.append(translated_sentence)\n",
    "\n",
    "    return translated_sentences\n",
    "\n",
    "\n",
    "def evaluate_test_set_bleu(model, test_dataloader, de_tokenizer):\n",
    "    \"\"\"\n",
    "    在测试集上评估模型的BLEU分数。\n",
    "\n",
    "    参数:\n",
    "    model: 训练好的Transformer模型。\n",
    "    test_dataloader: 测试数据的数据加载器。\n",
    "    de_tokenizer: 目标语言的词汇表。\n",
    "\n",
    "    返回:\n",
    "    float: 测试集的BLEU分数。\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    bleu = 0\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        src, tgt_output = batch\n",
    "        src, tgt = src.to(DEVICE), tgt_output.to(DEVICE)\n",
    "        tgt_sentences = [' '.join([INDEX_TO_ZH_VOCAB.get(token.item(), '<unk>') for token in sequence if token.item() not in [ZH_VOCAB['<pad>'], ZH_VOCAB['<sos>'], ZH_VOCAB['<eos>']]]) for sequence in tgt_output]\n",
    "\n",
    "        translations = inference(model, src, de_tokenizer)\n",
    "        \n",
    "        bleu_score2 = sacrebleu.corpus_bleu([translations[0]],  [[tgt_sentences[0]]])\n",
    "        \n",
    "        for i in range(len(translations)):\n",
    "            bleu += sacrebleu.corpus_bleu([translations[i]], [[tgt_sentences[i]]]).score\n",
    "        \n",
    "        print(\"\\n test集第\" + str(n*128) +'句话：')\n",
    "        print(\"输入英语     :\", ' '.join([INDEX_TO_EN_VOCAB.get(i.item(), '<unk>') for i in src[0] if INDEX_TO_EN_VOCAB.get(i.item()) not in ['<sos>', '<eos>', '<pad>'] ])) # i是一个tensor\n",
    "        print(\"GT          :\", tgt_sentences[0])\n",
    "        print(\"模型预测     :\", translations[0])\n",
    "        print(\"该句话BLEU得分：{:.2f}\".format(bleu_score2.score))\n",
    "        n += 1\n",
    "\n",
    "    return bleu/len(test_dataset)\n",
    "\n",
    "# Usage example\n",
    "test_bleu = evaluate_test_set_bleu(model, test_dataloader, ZH_VOCAB)\n",
    "print(\"test集每个句子的平均 BLEU 分数:\", test_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
