{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorchtext:#提供了文本处理的工具和数据集，常用于自然语言处理（NLP）任务\\nde_core_news_sm:#下载并安装spaCy的德语小型模型de_core_news_sm\\nen_core_web_sm:#下载并安装spaCy的英语小型模型\\nportalocker:#用于文件锁定的库，以防止多个进程同时写入同一个文件。\\ntorchdata:#PyTorch的一个扩展库，提供了数据加载、预处理功能，以及多种数据集的接口\\nsacrebleu:#提供了标准化的BLEU分数计算方法，用于评估机器翻译和其他生成任务的性能。\\ntorchsummaryX:#这个库为PyTorch模型提供了详细的结构摘要输出，包括每层的形状、参数数量等信息\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "torchtext:#提供了文本处理的工具和数据集，常用于自然语言处理（NLP）任务\n",
    "de_core_news_sm:#下载并安装spaCy的德语小型模型de_core_news_sm\n",
    "en_core_web_sm:#下载并安装spaCy的英语小型模型\n",
    "portalocker:#用于文件锁定的库，以防止多个进程同时写入同一个文件。\n",
    "torchdata:#PyTorch的一个扩展库，提供了数据加载、预处理功能，以及多种数据集的接口\n",
    "sacrebleu:#提供了标准化的BLEU分数计算方法，用于评估机器翻译和其他生成任务的性能。\n",
    "torchsummaryX:#这个库为PyTorch模型提供了详细的结构摘要输出，包括每层的形状、参数数量等信息\n",
    "\"\"\"\n",
    "# # Uncomment to install\n",
    "# !pip install -U torchtext -q \n",
    "# !python -m spacy download \"de_core_news_sm\" \n",
    "# !python -m spacy download \"en_core_web_sm\" \n",
    "# !pip install portalocker>=2.0 -q \n",
    "# !pip install -U torchdata -q \n",
    "# !pip install sacrebleu -q \n",
    "# !pip install torchsummaryX -q \n",
    "# # You may need to restart your runtime after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import sacrebleu\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import Multi30k\n",
    "from typing import Tuple\n",
    "import torchdata\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 数据集和分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell if you get a UTF Encoding Error\n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文件夹，并将数据集文件夹中相关文件解压并放到刚创建的文件中\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# 创建所需的文件夹\n",
    "folders = ['Multi30k', 'Multi30k/train', 'Multi30k/val', 'Multi30k/test']\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# 定义一个解压缩并复制文件的函数\n",
    "def gunzip_shutil(source_filepath, dest_filepath):\n",
    "    with gzip.open(source_filepath, 'rb') as f_in:\n",
    "        with open(dest_filepath, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# 执行解压缩\n",
    "source_base_path = 'E:/project_2023/multi30k-dataset/data/task1/raw'\n",
    "dest_base_path = 'Multi30k'\n",
    "file_pairs = [\n",
    "    ('train.en.gz', 'train/train.en'),\n",
    "    ('train.de.gz', 'train/train.de'),\n",
    "    ('val.en.gz', 'val/val.en'),\n",
    "    ('val.de.gz', 'val/val.de'),\n",
    "    ('test_2016_flickr.en.gz', 'test/test.en'),\n",
    "    ('test_2016_flickr.de.gz', 'test/test.de')\n",
    "]\n",
    "\n",
    "for source_file, dest_file in file_pairs:\n",
    "    source_filepath = os.path.join(source_base_path, source_file)\n",
    "    dest_filepath = os.path.join(dest_base_path, dest_file)\n",
    "    gunzip_shutil(source_filepath, dest_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29000/29000 [00:00<00:00, 46719.01it/s]\n",
      "100%|██████████| 29000/29000 [00:00<00:00, 30010.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocab Size English 10837\n",
      "\n",
      "Vocab Size German 19214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from torchtext.data.utils import get_tokenizer  # 用于获取分词器\n",
    "from torchtext.datasets import Multi30k  # Multi30k数据集\n",
    "from collections import Counter  # 计数器，用于统计词频\n",
    "from tqdm import tqdm  # 进度条库，用于显示进度\n",
    "\n",
    "root = '/content/Multi30k/'  # 定义数据集的根目录\n",
    "\n",
    "# 获取英文和德文的分词器，使用的是spacy库的分词器\n",
    "en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "de_tokenizer = get_tokenizer(\"spacy\", language=\"de_core_news_sm\")\n",
    "\n",
    "# 定义英文文本的分词函数\n",
    "def tokenize_en(text):\n",
    "    doc = en_tokenizer(str(text))\n",
    "    return [token for token in doc]\n",
    "\n",
    "# 定义德文文本的分词函数\n",
    "def tokenize_de(text):\n",
    "    doc = de_tokenizer(str(text))\n",
    "    return [token for token in doc]\n",
    "\n",
    "# 定义词汇表类\n",
    "class Vocab:\n",
    "\n",
    "    def __init__(self, tokenizer, min_freq=2, data=None, special_tokens=['<pad>', '<sos>', '<eos>', '<unk>']):\n",
    "        # 初始化词汇表对象\n",
    "        self.tokenizer = tokenizer  # 分词器\n",
    "        self.min_freq = min_freq  # 最小词频阈值\n",
    "        self.special_tokens = special_tokens  # 特殊标记列表\n",
    "        self.build_vocab(data)  # 构建词汇表\n",
    "\n",
    "    def build_vocab(self, data):\n",
    "        # 构建词汇表的方法\n",
    "        counter = Counter()  # 创建计数器\n",
    "        for text in tqdm(data):\n",
    "            tokens = self.tokenizer(text)  # 对文本进行分词\n",
    "            counter.update(tokens)  # 更新词频统计\n",
    "\n",
    "        # 过滤掉词频小于最小词频阈值的词\n",
    "        tokens = [token for token, freq in counter.items() if freq >= self.min_freq]\n",
    "\n",
    "        # 在词列表前加上特殊标记\n",
    "        tokens = self.special_tokens + tokens\n",
    "\n",
    "        # 创建字符串到索引的映射字典\n",
    "        self.stoi = {token: index for index, token in enumerate(tokens)}\n",
    "        # 索引到字符串的映射列表\n",
    "        self.itos = tokens  \n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回词汇表的大小\n",
    "        return len(self.stoi)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        # 根据词获取其索引，如果不存在则返回'<unk>'的索引\n",
    "        return self.stoi.get(token, self.stoi['<unk>'])\n",
    "\n",
    "en_file = \"Multi30k/train/train.en\"  # 英文文件路径\n",
    "de_file = \"Multi30k/train/train.de\"  # 德文文件路径\n",
    "\n",
    "# 打开英文文件并读取内容\n",
    "with open(en_file, \"r\", encoding=\"utf8\") as f:\n",
    "    train_data_en = [text.strip() for text in f.readlines()]\n",
    "\n",
    "# 打开德文文件并读取内容\n",
    "with open(de_file, \"r\", encoding=\"utf8\") as f:\n",
    "    train_data_de = [text.strip() for text in f.readlines()]\n",
    "\n",
    "# 使用英文和德文的训练数据创建词汇表对象\n",
    "EN_VOCAB = Vocab(tokenize_en, min_freq=1, data=train_data_en)\n",
    "DE_VOCAB = Vocab(tokenize_de, min_freq=1, data=train_data_de)\n",
    "\n",
    "# 打印英文和德文词汇表的大小\n",
    "print(\"\\nVocab Size English\", len(EN_VOCAB))\n",
    "print(\"\\nVocab Size German\", len(DE_VOCAB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocab at 0x2579cdbccd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个自定义的PyTorch数据集TranslationDataset，用于加载和准备机器翻译任务的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入PyTorch相关库\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 定义一个用于机器翻译的数据集类，继承自PyTorch的Dataset类\n",
    "class TranslationDataset(Dataset):\n",
    "\n",
    "    # 构造函数初始化数据集对象\n",
    "    def __init__(self, en_data, de_data, src_tokenizer, tgt_tokenizer, src_vocab, tgt_vocab):\n",
    "        # 初始化英文数据列表\n",
    "        self.en_data = en_data\n",
    "        # 初始化德文数据列表\n",
    "        self.de_data = de_data\n",
    "        # 源语言（英文）的分词器\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        # 目标语言（德文）的分词器\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        # 源语言的词汇表，用于将单词转换为索引\n",
    "        self.src_vocab = src_vocab\n",
    "        # 目标语言的词汇表，用于将单词转换为索引\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    # 该方法根据索引获取数据集中的特定项目\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引获取源语言和目标语言的文本\n",
    "        src_txt, tgt_txt = self.en_data[index], self.de_data[index]\n",
    "\n",
    "        # 使用分词器对文本进行分词，并使用词汇表将单词转换为索引\n",
    "        src_tokens = [self.src_vocab[token] for token in self.src_tokenizer(src_txt)]\n",
    "        tgt_tokens = [self.tgt_vocab[token] for token in self.tgt_tokenizer(tgt_txt)]\n",
    "\n",
    "        # 在序列的开始和结束分别添加特殊标记<sos>和<eos>\n",
    "        src_tokens = [self.src_vocab['<sos>']] + src_tokens + [self.src_vocab['<eos>']]\n",
    "        tgt_tokens = [self.tgt_vocab['<sos>']] + tgt_tokens + [self.tgt_vocab['<eos>']]\n",
    "\n",
    "        # 将索引列表转换为PyTorch张量\n",
    "        src_tensor = torch.LongTensor(src_tokens)\n",
    "        tgt_tensor = torch.LongTensor(tgt_tokens)\n",
    "\n",
    "        # 返回处理好的源语言和目标语言张量\n",
    "        return src_tensor, tgt_tensor\n",
    "\n",
    "    # 该方法返回数据集中的项目总数\n",
    "    def __len__(self):\n",
    "        # 确保源语言和目标语言数据列表的长度相等\n",
    "        assert len(self.en_data) == len(self.de_data)\n",
    "        # 返回数据集的大小\n",
    "        return len(self.en_data)\n",
    "\n",
    "    # 自定义批处理函数，用于数据加载器在加载批次数据时的数据处理\n",
    "    def collate_fn(self, batch):\n",
    "        # 将批次中的数据分解为源语言和目标语言张量列表\n",
    "        src_tensors, tgt_tensors = zip(*batch)\n",
    "        # 使用pad_sequence对序列进行填充，使得批次中的所有序列长度相等，填充值为<pad>标记的索引\n",
    "        src_tensors = torch.nn.utils.rnn.pad_sequence(src_tensors, padding_value=self.src_vocab['<pad>'], batch_first=True)\n",
    "        tgt_tensors = torch.nn.utils.rnn.pad_sequence(tgt_tensors, padding_value=self.tgt_vocab['<pad>'], batch_first=True)\n",
    "\n",
    "        # 返回处理好的源语言和目标语言批次数据\n",
    "        return src_tensors, tgt_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集文件路径\n",
    "en_file = \"Multi30k/train/train.en\"\n",
    "de_file = \"Multi30k/train/train.de\"\n",
    "\n",
    "# 打开英文训练集文件，并读取其内容。去除每行文本的首尾空白字符。\n",
    "with open(en_file, \"r\", encoding=\"utf8\") as f:\n",
    "    train_data_en = [text.strip() for text in f.readlines()]\n",
    "\n",
    "# 打开德文训练集文件，并读取其内容。同样去除每行文本的首尾空白字符。\n",
    "with open(de_file, \"r\", encoding=\"utf8\") as f:\n",
    "    train_data_de = [text.strip() for text in f.readlines()]\n",
    "\n",
    "\n",
    "\n",
    "# 定义验证集文件路径\n",
    "en_file = \"Multi30k/val/val.en\"\n",
    "de_file = \"Multi30k/val/val.de\"\n",
    "\n",
    "# 打开英文验证集文件，并读取其内容，处理方式同上。\n",
    "with open(en_file, \"r\", encoding=\"utf8\") as f:\n",
    "    val_data_en = [text.strip() for text in f.readlines()]\n",
    "\n",
    "# 打开德文验证集文件，并读取其内容，处理方式同上。\n",
    "with open(de_file, \"r\", encoding=\"utf8\") as f:\n",
    "    val_data_de = [text.strip() for text in f.readlines()]\n",
    "\n",
    "\n",
    "\n",
    "# 定义测试集文件路径\n",
    "en_file = \"Multi30k/test/test.en\"\n",
    "de_file = \"Multi30k/test/test.de\"\n",
    "\n",
    "# 打开英文测试集文件，并读取其内容，处理方式同上。\n",
    "with open(en_file, \"r\", encoding=\"utf8\") as f:\n",
    "    test_data_en = [text.strip() for text in f.readlines()]\n",
    "\n",
    "# 打开德文测试集文件，并读取其内容，处理方式同上。\n",
    "with open(de_file, \"r\", encoding=\"utf8\") as f:\n",
    "    test_data_de = [text.strip() for text in f.readlines()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 使用读取的训练集数据创建TranslationDataset对象。\n",
    "train_dataset = TranslationDataset(train_data_en, train_data_de, tokenize_en, tokenize_de, EN_VOCAB, DE_VOCAB)\n",
    "\n",
    "# 使用读取的验证集数据创建TranslationDataset对象。\n",
    "val_dataset = TranslationDataset(val_data_en, val_data_de, tokenize_en, tokenize_de, EN_VOCAB, DE_VOCAB)\n",
    "\n",
    "# 使用读取的测试集数据创建TranslationDataset对象。\n",
    "test_dataset = TranslationDataset(test_data_en, test_data_de, tokenize_en, tokenize_de, EN_VOCAB, DE_VOCAB)\n",
    "\n",
    "# 定义批处理大小。\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 创建DataLoader对象，用于训练集数据的批量加载和打乱。\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "# 创建DataLoader对象，用于验证集数据的批量加载，不打乱数据。\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "# 创建DataLoader对象，用于测试集数据的批量加载，不打乱数据。\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=test_dataset.collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看序列实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2]),\n",
       " tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<sos> Two young , White males are outside near many bushes . <eos>',\n",
       " '<sos> Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche . <eos>')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([EN_VOCAB.itos[i] for i in train_dataset[0][0]]), ' '.join([DE_VOCAB.itos[i] for i in train_dataset[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A man in an orange hat starring at something.',\n",
       " 'Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_en[0], test_data_de[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<sos> A man in an orange hat starring at something . <eos>',\n",
       " '<sos> Ein Mann mit einem orangefarbenen Hut , der etwas <unk> . <eos>')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([EN_VOCAB.itos[i] for i in test_dataset[0][0]]), ' '.join([DE_VOCAB.itos[i] for i in test_dataset[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 位置编码 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数学库\n",
    "import math\n",
    "\n",
    "# PositionalEncoding类继承自nn.Module，是一个PyTorch模块\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    # 类的初始化方法\n",
    "    def __init__(self, d_model, max_seq_len, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化PositionalEncoding模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入向量的维度。\n",
    "        max_seq_len (int): 输入序列的最大长度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        # 调用父类的初始化方法\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 定义一个dropout层，用于在位置编码加到输入向量之后进行dropout操作\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 初始化一个位置编码矩阵，全为零，形状为(max_seq_len, d_model)\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # 生成一个位置索引向量，形状为(max_seq_len, 1)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # 生成除数项，用于计算正弦和余弦函数的参数，形状为(d_model / 2,)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        # 计算位置编码的正弦部分，填充到偶数位置\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算位置编码的余弦部分，填充到奇数位置\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 增加一个维度，使pe的形状为(1, max_seq_len, d_model)，方便后续的广播操作\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 将位置编码矩阵注册为一个buffer，这样它就可以被保存在模型的state_dict中了，\n",
    "        # 虽然它不是一个可学习的参数。\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    # 定义前向传播方法\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        PositionalEncoding的前向传播方法。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 将位置编码加到输入张量上，使用广播机制匹配序列长度\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        # 对加上位置编码后的输入进行dropout操作\n",
    "        x = self.dropout(x)\n",
    "        # 返回处理后的张量\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Multi-Head Attention模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入PyTorch库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义多头自注意力模块，继承自nn.Module\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"\n",
    "        初始化多头自注意力模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        num_heads (int): 注意力头的数量。\n",
    "        \"\"\"\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model  # 保存输入维度\n",
    "        self.num_heads = num_heads  # 保存头的数量\n",
    "        self.head_dim = d_model // num_heads  # 计算每个头的维度\n",
    "\n",
    "        # 确保d_model能被num_heads整除，保证等分\n",
    "        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        # 定义全连接层，用于生成查询、键、值\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 定义输出全连接层\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        多头自注意力的前向传播。\n",
    "\n",
    "        参数:\n",
    "        q (Tensor): 查询张量，形状为(batch_size, seq_length, d_model)。\n",
    "        k (Tensor): 键张量，形状为(batch_size, seq_length, d_model)。\n",
    "        v (Tensor): 值张量，形状为(batch_size, seq_length, d_model)。\n",
    "        mask (Tensor, optional): 掩码张量，用于忽略某些元素，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # 将查询、键、值通过全连接层后，改变形状以适应多头处理\n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "\n",
    "        # 转置操作，以满足矩阵乘法的需求\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        # 计算注意力权重矩阵\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # 如果提供了掩码，则应用掩码\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # 应用softmax获取标准化的注意力权重\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        # 根据注意力权重计算输出值\n",
    "        out = torch.matmul(attn, v).transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        # 将输出通过最后一个全连接层\n",
    "        out = self.wo(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Add 和 Norm 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddNorm类继承自nn.Module，是PyTorch中的标准写法\n",
    "class AddNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        \"\"\"\n",
    "        初始化AddNorm模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        eps (float, optional): 为了数值稳定性而加入的一个小常数，默认值为1e-6。\n",
    "        \"\"\"\n",
    "        super(AddNorm, self).__init__()  # 调用父类的初始化函数\n",
    "        # 初始化一个层归一化（LayerNorm）模块，它会对输入张量的最后一维进行归一化\n",
    "        self.norm = nn.LayerNorm(d_model, eps=eps)\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        \"\"\"\n",
    "        AddNorm的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "        residual (Tensor): 残差张量，与输入张量形状相同。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状也为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 首先进行残差连接，即将输入张量和残差张量相加\n",
    "        out = x + residual\n",
    "        # 然后对相加后的结果进行层归一化处理\n",
    "        out = self.norm(out)\n",
    "\n",
    "        # 返回归一化后的输出张量\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Feed-Forward 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionwiseFeedForward类继承自nn.Module，是一个PyTorch模块\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化逐位置前馈网络模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        d_ff (int): 前馈网络隐藏层的维度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        # 定义第一个全连接层，将输入维度从d_model映射到d_ff\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        # 定义一个dropout层，用于防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 定义第二个全连接层，将维度从d_ff映射回d_model\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        逐位置前馈网络的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 通过第一个全连接层\n",
    "        out = self.linear1(x)\n",
    "        # 应用ReLU激活函数\n",
    "        out = F.relu(out)\n",
    "        # 应用dropout\n",
    "        out = self.dropout(out)\n",
    "        # 通过第二个全连接层\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # 返回最终的输出张量\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Encoder 类\n",
    "- Multi-Head Self-Attention layer\n",
    "- Add & Norm (Residual connection and Layer Normalization)\n",
    "- Position-wise Feed-Forward Network layer\n",
    "- Add & Norm (Residual connection and Layer Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EncoderBlock类继承自nn.Module，是一个PyTorch模块\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化编码器块模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        num_heads (int): 注意力机制中头的数量。\n",
    "        d_ff (int): 前馈网络中隐藏层的维度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        # 初始化多头自注意力层\n",
    "        self.self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        # 初始化第一个添加残差连接和层归一化的模块\n",
    "        self.norm1 = AddNorm(d_model)\n",
    "        # 初始化逐位置前馈网络\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        # 初始化第二个添加残差连接和层归一化的模块\n",
    "        self.norm2 = AddNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        编码器块的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "        mask (Tensor, optional): 掩码张量，用于忽略某些元素，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 通过多头自注意力层处理输入\n",
    "        x1 = self.self_attn(q=x, k=x, v=x, mask=mask)\n",
    "        # 应用残差连接和层归一化\n",
    "        x = self.norm1(x, x1)\n",
    "        # 通过逐位置前馈网络处理\n",
    "        x1 = self.ffn(x)\n",
    "        # 再次应用残差连接和层归一化\n",
    "        x = self.norm2(x, x1)\n",
    "\n",
    "        # 返回最终的输出\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Decoder 类\n",
    "- Masked Multi-Head Self-Attention layer\n",
    "- Add & Norm (Residual connection and Layer Normalization)\n",
    "- Encoder-Decoder Multi-Head Attention layer\n",
    "- Add & Norm (Residual connection and Layer Normalization)\n",
    "- Position-wise Feed-Forward Network layer\n",
    "- Add & Norm (Residual connection and Layer Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecoderBlock类继承自nn.Module，是一个PyTorch模块\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化解码器块模块。\n",
    "\n",
    "        参数:\n",
    "        d_model (int): 输入张量的维度。\n",
    "        num_heads (int): 注意力机制中头的数量。\n",
    "        d_ff (int): 前馈网络中隐藏层的维度。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # 初始化自注意力层\n",
    "        self.self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        # 初始化第一个残差连接和层归一化\n",
    "        self.norm1 = AddNorm(d_model)\n",
    "        # 初始化编码器-解码器注意力层，用于关注编码器的输出\n",
    "        self.enc_dec_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        # 初始化第二个残差连接和层归一化\n",
    "        self.norm2 = AddNorm(d_model)\n",
    "        # 初始化逐位置前馈网络\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        # 初始化第三个残差连接和层归一化\n",
    "        self.norm3 = AddNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        解码器块的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        x (Tensor): 目标输入张量，形状为(batch_size, seq_length, d_model)。\n",
    "        enc_output (Tensor): 编码器输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        src_mask (Tensor, optional): 来源掩码张量，用于忽略某些元素，针对编码器输出，默认为None。\n",
    "        tgt_mask (Tensor, optional): 目标掩码张量，用于忽略某些元素，针对自注意力层，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, seq_length, d_model)。\n",
    "        \"\"\"\n",
    "        # 通过自注意力层处理输入\n",
    "        x1 = self.self_attn(q=x, k=x, v=x, mask=tgt_mask)\n",
    "        # 应用残差连接和层归一化\n",
    "        x = self.norm1(x, x1)\n",
    "        # 通过编码器-解码器注意力层处理，关注编码器的输出\n",
    "        x1 = self.enc_dec_attn(q=x, k=enc_output, v=enc_output, mask=src_mask)\n",
    "        # 再次应用残差连接和层归一化\n",
    "        x = self.norm2(x, x1)\n",
    "        # 通过逐位置前馈网络处理\n",
    "        x1 = self.ffn(x)\n",
    "        # 最后再次应用残差连接和层归一化\n",
    "        x = self.norm3(x, x1)\n",
    "\n",
    "        # 返回最终的输出\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 transformer 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer类继承自nn.Module，是一个PyTorch模块\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, D_MODEL, num_heads, d_ff, max_seq_len, num_layers, dropout=0.1):\n",
    "        \"\"\"\n",
    "        初始化Transformer模块。\n",
    "\n",
    "        参数:\n",
    "        src_vocab_size (int): 源词汇表的大小。\n",
    "        tgt_vocab_size (int): 目标词汇表的大小。\n",
    "        D_MODEL (int): 嵌入向量的维度。\n",
    "        num_heads (int): 注意力机制中头的数量。\n",
    "        d_ff (int): 前馈网络中隐藏层的维度。\n",
    "        max_seq_len (int): 输入序列的最大长度。\n",
    "        num_layers (int): 编码器和解码器中层的数量。\n",
    "        dropout (float, optional): Dropout概率，默认为0.1。\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        # 初始化源词嵌入层\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, D_MODEL)\n",
    "        # 初始化目标词嵌入层\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, D_MODEL)\n",
    "        # 初始化位置编码\n",
    "        self.pos_encoding = PositionalEncoding(D_MODEL, max_seq_len, dropout)\n",
    "\n",
    "        # 初始化编码器层，使用ModuleList容纳多个EncoderBlock实例\n",
    "        self.encoder_layers = nn.ModuleList([EncoderBlock(D_MODEL, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        # 初始化解码器层，同样使用ModuleList\n",
    "        self.decoder_layers = nn.ModuleList([DecoderBlock(D_MODEL, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        # 初始化一个全连接层，用于将解码器的输出映射到目标词汇空间\n",
    "        self.fc = nn.Linear(D_MODEL, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        Transformer的前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        src (Tensor): 源输入张量，形状为(batch_size, src_seq_length)。\n",
    "        tgt (Tensor): 目标输入张量，形状为(batch_size, tgt_seq_length)。\n",
    "        src_mask (Tensor, optional): 源掩码张量，用于忽略某些元素，默认为None。\n",
    "        tgt_mask (Tensor, optional): 目标掩码张量，用于忽略某些元素，默认为None。\n",
    "\n",
    "        返回:\n",
    "        Tensor: 输出张量，形状为(batch_size, tgt_seq_length, tgt_vocab_size)。\n",
    "        \"\"\"\n",
    "        # 对源序列进行词嵌入和位置编码\n",
    "        src = self.src_embedding(src)\n",
    "        src = self.pos_encoding(src)\n",
    "\n",
    "        # 对目标序列进行词嵌入和位置编码\n",
    "        tgt = self.tgt_embedding(tgt)\n",
    "        tgt = self.pos_encoding(tgt)\n",
    "\n",
    "        # 依次通过编码器层\n",
    "        for layer in self.encoder_layers:\n",
    "            src = layer(src, src_mask)\n",
    "\n",
    "        # 依次通过解码器层，需要提供编码器的输出和掩码信息\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt = layer(tgt, src, src_mask, tgt_mask)\n",
    "\n",
    "        # 通过最后的全连接层，映射到目标词汇空间\n",
    "        out = self.fc(tgt)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练时的超参数\n",
    "NUM_EPOCHS      = 20            # 训练的轮数\n",
    "D_MODEL         = 256           # 模型中嵌入向量的维度\n",
    "ATTN_HEADS      = 8             # 多头注意力中头的数量\n",
    "NUM_LAYERS      = 3             # 编码器和解码器层重复的次数\n",
    "FEEDFORWARD_DIM = 512           # 前馈网络中隐藏层的维度\n",
    "DROPOUT         = 0.1           # Dropout概率，用于防止过拟合\n",
    "MAX_SEQ_LEN     = 150           # 输入序列的最大长度\n",
    "SRC_VOCAB_SIZE  = len(EN_VOCAB)  # 源语言词汇表的大小\n",
    "TGT_VOCAB_SIZE  = len(DE_VOCAB)  # 目标语言词汇表的大小\n",
    "LR              = 0             # 学习率，这里设置为0可能是为了后续调整\n",
    "\n",
    "# 设备配置，优先使用GPU，如果没有GPU则使用CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NoamScheduler类负责根据训练步骤动态调整学习率\n",
    "class NoamScheduler:\n",
    "\n",
    "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
    "        \"\"\"\n",
    "        初始化NoamScheduler。\n",
    "\n",
    "        参数:\n",
    "        optimizer: 用于训练的优化器。\n",
    "        d_model (int): 模型中嵌入向量的维度。\n",
    "        warmup_steps (int): 预热步数，在此步数之前学习率会线性增加。\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.current_step = 0  # 初始化当前步数\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        更新学习率并增加步数。\n",
    "        \"\"\"\n",
    "        self.current_step += 1  # 每调用一次，步数增加1\n",
    "        lr = self.learning_rate()  # 计算当前步数的学习率\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr  # 更新优化器中的学习率\n",
    "\n",
    "    def learning_rate(self):\n",
    "        \"\"\"\n",
    "        根据当前步数计算学习率。\n",
    "        \"\"\"\n",
    "        step = self.current_step\n",
    "        # 学习率随着步数先增后减，增加部分线性增加至warmup_steps，之后随步数的增加而减小\n",
    "        return (self.d_model ** -0.5) * min(step ** -0.5, step * self.warmup_steps ** -1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化Transformer模型，并将其移动到适当的设备上\n",
    "model = Transformer(SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, D_MODEL, ATTN_HEADS, FEEDFORWARD_DIM, MAX_SEQ_LEN, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
    "\n",
    "# 初始化优化器，这里使用AdamW优化器，它是Adam优化器的一个变种，添加了权重衰减\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9, weight_decay=5e-2)\n",
    "\n",
    "# 根据训练数据加载器的长度计算预热步数\n",
    "warmup_steps = 2 * len(train_dataloader)\n",
    "\n",
    "# 使用NoamScheduler作为学习率调度器\n",
    "scheduler = NoamScheduler(optimizer, d_model=D_MODEL, warmup_steps=warmup_steps)\n",
    "\n",
    "# 初始化损失函数，使用交叉熵损失，并忽略'<pad>'标记的损失，同时应用标签平滑\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=DE_VOCAB['<pad>'], label_smoothing=0.1)\n",
    "\n",
    "# 初始化梯度缩放器，用于混合精度训练，有助于提高训练速度和减少内存消耗\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "def generate_tgt_mask(tgt, pad_idx):\n",
    "    \"\"\"\n",
    "    生成目标序列的掩码，遮蔽未来位置以及填充位置。\n",
    "    \n",
    "    参数:\n",
    "    tgt (Tensor): 目标序列。\n",
    "    pad_idx (int): `<pad>`标记的索引。\n",
    "    \n",
    "    返回:\n",
    "    Tensor: 组合掩码。\n",
    "    \"\"\"\n",
    "    seq_len = tgt.size(1)\n",
    "    # 生成一个下三角矩阵，用于屏蔽未来的信息\n",
    "    no_future_mask = torch.tril(torch.ones((seq_len, seq_len), device=DEVICE)).bool()\n",
    "    # 生成一个填充位置的掩码\n",
    "    pad_mask = (tgt != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    # 将两个掩码相与，得到最终的掩码\n",
    "    combined_mask = pad_mask & no_future_mask\n",
    "    return combined_mask\n",
    "\n",
    "\n",
    "def generate_src_mask(src, pad_idx):\n",
    "    \"\"\"\n",
    "    生成源序列的掩码，遮蔽填充位置。\n",
    "    \n",
    "    参数:\n",
    "    src (Tensor): 源序列。\n",
    "    pad_idx (int): `<pad>`标记的索引。\n",
    "    \n",
    "    返回:\n",
    "    Tensor: 源序列的掩码。\n",
    "    \"\"\"\n",
    "    mask = (src != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def calculate_bleu(tgt_output, output):\n",
    "    \"\"\"\n",
    "    计算BLEU分数。\n",
    "    \n",
    "    参数:\n",
    "    tgt_output (Tensor): 真实的目标序列。\n",
    "    output (Tensor): 模型生成的输出序列。\n",
    "    \n",
    "    返回:\n",
    "    float: BLEU分数。\n",
    "    \"\"\"\n",
    "    tgt_output = tgt_output.cpu().numpy()\n",
    "    output = output.cpu().numpy()\n",
    "\n",
    "    refs = []  # 参考序列\n",
    "    hyps = []  # 假设序列\n",
    "\n",
    "    # 需要排除的标记\n",
    "    excluded_tokens = (DE_VOCAB['<pad>'], DE_VOCAB['<eos>'], DE_VOCAB['<sos>'])\n",
    "    for tgt, pred in zip(tgt_output, output):\n",
    "        # 将索引转换为单词，排除特定标记\n",
    "        ref = ' '.join([DE_VOCAB.itos[t] for t in tgt if t not in excluded_tokens])\n",
    "        hyp = ' '.join([DE_VOCAB.itos[t] for t in pred if t not in excluded_tokens])\n",
    "\n",
    "        refs.append(ref)\n",
    "        hyps.append(hyp)\n",
    "\n",
    "    # 计算BLEU分数\n",
    "    bleu = sacrebleu.corpus_bleu(hyps, [refs], force=True).score\n",
    "    return bleu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "                                            Kernel Shape      Output Shape  \\\n",
      "Layer                                                                        \n",
      "0_src_embedding                             [256, 10837]    [128, 25, 256]   \n",
      "1_pos_encoding.Dropout_dropout                         -    [128, 25, 256]   \n",
      "2_tgt_embedding                             [256, 19214]    [128, 27, 256]   \n",
      "3_pos_encoding.Dropout_dropout                         -    [128, 27, 256]   \n",
      "4_encoder_layers.0.self_attn.Linear_wq        [256, 256]    [128, 25, 256]   \n",
      "5_encoder_layers.0.self_attn.Linear_wk        [256, 256]    [128, 25, 256]   \n",
      "6_encoder_layers.0.self_attn.Linear_wv        [256, 256]    [128, 25, 256]   \n",
      "7_encoder_layers.0.self_attn.Linear_wo        [256, 256]    [128, 25, 256]   \n",
      "8_encoder_layers.0.norm1.LayerNorm_norm            [256]    [128, 25, 256]   \n",
      "9_encoder_layers.0.ffn.Linear_linear1         [256, 512]    [128, 25, 512]   \n",
      "10_encoder_layers.0.ffn.Dropout_dropout                -    [128, 25, 512]   \n",
      "11_encoder_layers.0.ffn.Linear_linear2        [512, 256]    [128, 25, 256]   \n",
      "12_encoder_layers.0.norm2.LayerNorm_norm           [256]    [128, 25, 256]   \n",
      "13_encoder_layers.1.self_attn.Linear_wq       [256, 256]    [128, 25, 256]   \n",
      "14_encoder_layers.1.self_attn.Linear_wk       [256, 256]    [128, 25, 256]   \n",
      "15_encoder_layers.1.self_attn.Linear_wv       [256, 256]    [128, 25, 256]   \n",
      "16_encoder_layers.1.self_attn.Linear_wo       [256, 256]    [128, 25, 256]   \n",
      "17_encoder_layers.1.norm1.LayerNorm_norm           [256]    [128, 25, 256]   \n",
      "18_encoder_layers.1.ffn.Linear_linear1        [256, 512]    [128, 25, 512]   \n",
      "19_encoder_layers.1.ffn.Dropout_dropout                -    [128, 25, 512]   \n",
      "20_encoder_layers.1.ffn.Linear_linear2        [512, 256]    [128, 25, 256]   \n",
      "21_encoder_layers.1.norm2.LayerNorm_norm           [256]    [128, 25, 256]   \n",
      "22_encoder_layers.2.self_attn.Linear_wq       [256, 256]    [128, 25, 256]   \n",
      "23_encoder_layers.2.self_attn.Linear_wk       [256, 256]    [128, 25, 256]   \n",
      "24_encoder_layers.2.self_attn.Linear_wv       [256, 256]    [128, 25, 256]   \n",
      "25_encoder_layers.2.self_attn.Linear_wo       [256, 256]    [128, 25, 256]   \n",
      "26_encoder_layers.2.norm1.LayerNorm_norm           [256]    [128, 25, 256]   \n",
      "27_encoder_layers.2.ffn.Linear_linear1        [256, 512]    [128, 25, 512]   \n",
      "28_encoder_layers.2.ffn.Dropout_dropout                -    [128, 25, 512]   \n",
      "29_encoder_layers.2.ffn.Linear_linear2        [512, 256]    [128, 25, 256]   \n",
      "30_encoder_layers.2.norm2.LayerNorm_norm           [256]    [128, 25, 256]   \n",
      "31_decoder_layers.0.self_attn.Linear_wq       [256, 256]    [128, 27, 256]   \n",
      "32_decoder_layers.0.self_attn.Linear_wk       [256, 256]    [128, 27, 256]   \n",
      "33_decoder_layers.0.self_attn.Linear_wv       [256, 256]    [128, 27, 256]   \n",
      "34_decoder_layers.0.self_attn.Linear_wo       [256, 256]    [128, 27, 256]   \n",
      "35_decoder_layers.0.norm1.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "36_decoder_layers.0.enc_dec_attn.Linear_wq    [256, 256]    [128, 27, 256]   \n",
      "37_decoder_layers.0.enc_dec_attn.Linear_wk    [256, 256]    [128, 25, 256]   \n",
      "38_decoder_layers.0.enc_dec_attn.Linear_wv    [256, 256]    [128, 25, 256]   \n",
      "39_decoder_layers.0.enc_dec_attn.Linear_wo    [256, 256]    [128, 27, 256]   \n",
      "40_decoder_layers.0.norm2.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "41_decoder_layers.0.ffn.Linear_linear1        [256, 512]    [128, 27, 512]   \n",
      "42_decoder_layers.0.ffn.Dropout_dropout                -    [128, 27, 512]   \n",
      "43_decoder_layers.0.ffn.Linear_linear2        [512, 256]    [128, 27, 256]   \n",
      "44_decoder_layers.0.norm3.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "45_decoder_layers.1.self_attn.Linear_wq       [256, 256]    [128, 27, 256]   \n",
      "46_decoder_layers.1.self_attn.Linear_wk       [256, 256]    [128, 27, 256]   \n",
      "47_decoder_layers.1.self_attn.Linear_wv       [256, 256]    [128, 27, 256]   \n",
      "48_decoder_layers.1.self_attn.Linear_wo       [256, 256]    [128, 27, 256]   \n",
      "49_decoder_layers.1.norm1.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "50_decoder_layers.1.enc_dec_attn.Linear_wq    [256, 256]    [128, 27, 256]   \n",
      "51_decoder_layers.1.enc_dec_attn.Linear_wk    [256, 256]    [128, 25, 256]   \n",
      "52_decoder_layers.1.enc_dec_attn.Linear_wv    [256, 256]    [128, 25, 256]   \n",
      "53_decoder_layers.1.enc_dec_attn.Linear_wo    [256, 256]    [128, 27, 256]   \n",
      "54_decoder_layers.1.norm2.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "55_decoder_layers.1.ffn.Linear_linear1        [256, 512]    [128, 27, 512]   \n",
      "56_decoder_layers.1.ffn.Dropout_dropout                -    [128, 27, 512]   \n",
      "57_decoder_layers.1.ffn.Linear_linear2        [512, 256]    [128, 27, 256]   \n",
      "58_decoder_layers.1.norm3.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "59_decoder_layers.2.self_attn.Linear_wq       [256, 256]    [128, 27, 256]   \n",
      "60_decoder_layers.2.self_attn.Linear_wk       [256, 256]    [128, 27, 256]   \n",
      "61_decoder_layers.2.self_attn.Linear_wv       [256, 256]    [128, 27, 256]   \n",
      "62_decoder_layers.2.self_attn.Linear_wo       [256, 256]    [128, 27, 256]   \n",
      "63_decoder_layers.2.norm1.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "64_decoder_layers.2.enc_dec_attn.Linear_wq    [256, 256]    [128, 27, 256]   \n",
      "65_decoder_layers.2.enc_dec_attn.Linear_wk    [256, 256]    [128, 25, 256]   \n",
      "66_decoder_layers.2.enc_dec_attn.Linear_wv    [256, 256]    [128, 25, 256]   \n",
      "67_decoder_layers.2.enc_dec_attn.Linear_wo    [256, 256]    [128, 27, 256]   \n",
      "68_decoder_layers.2.norm2.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "69_decoder_layers.2.ffn.Linear_linear1        [256, 512]    [128, 27, 512]   \n",
      "70_decoder_layers.2.ffn.Dropout_dropout                -    [128, 27, 512]   \n",
      "71_decoder_layers.2.ffn.Linear_linear2        [512, 256]    [128, 27, 256]   \n",
      "72_decoder_layers.2.norm3.LayerNorm_norm           [256]    [128, 27, 256]   \n",
      "73_fc                                       [256, 19214]  [128, 27, 19214]   \n",
      "\n",
      "                                               Params  Mult-Adds  \n",
      "Layer                                                             \n",
      "0_src_embedding                             2.774272M  2.774272M  \n",
      "1_pos_encoding.Dropout_dropout                      -          -  \n",
      "2_tgt_embedding                             4.918784M  4.918784M  \n",
      "3_pos_encoding.Dropout_dropout                      -          -  \n",
      "4_encoder_layers.0.self_attn.Linear_wq        65.792k    65.536k  \n",
      "5_encoder_layers.0.self_attn.Linear_wk        65.792k    65.536k  \n",
      "6_encoder_layers.0.self_attn.Linear_wv        65.792k    65.536k  \n",
      "7_encoder_layers.0.self_attn.Linear_wo        65.792k    65.536k  \n",
      "8_encoder_layers.0.norm1.LayerNorm_norm         512.0      256.0  \n",
      "9_encoder_layers.0.ffn.Linear_linear1        131.584k   131.072k  \n",
      "10_encoder_layers.0.ffn.Dropout_dropout             -          -  \n",
      "11_encoder_layers.0.ffn.Linear_linear2       131.328k   131.072k  \n",
      "12_encoder_layers.0.norm2.LayerNorm_norm        512.0      256.0  \n",
      "13_encoder_layers.1.self_attn.Linear_wq       65.792k    65.536k  \n",
      "14_encoder_layers.1.self_attn.Linear_wk       65.792k    65.536k  \n",
      "15_encoder_layers.1.self_attn.Linear_wv       65.792k    65.536k  \n",
      "16_encoder_layers.1.self_attn.Linear_wo       65.792k    65.536k  \n",
      "17_encoder_layers.1.norm1.LayerNorm_norm        512.0      256.0  \n",
      "18_encoder_layers.1.ffn.Linear_linear1       131.584k   131.072k  \n",
      "19_encoder_layers.1.ffn.Dropout_dropout             -          -  \n",
      "20_encoder_layers.1.ffn.Linear_linear2       131.328k   131.072k  \n",
      "21_encoder_layers.1.norm2.LayerNorm_norm        512.0      256.0  \n",
      "22_encoder_layers.2.self_attn.Linear_wq       65.792k    65.536k  \n",
      "23_encoder_layers.2.self_attn.Linear_wk       65.792k    65.536k  \n",
      "24_encoder_layers.2.self_attn.Linear_wv       65.792k    65.536k  \n",
      "25_encoder_layers.2.self_attn.Linear_wo       65.792k    65.536k  \n",
      "26_encoder_layers.2.norm1.LayerNorm_norm        512.0      256.0  \n",
      "27_encoder_layers.2.ffn.Linear_linear1       131.584k   131.072k  \n",
      "28_encoder_layers.2.ffn.Dropout_dropout             -          -  \n",
      "29_encoder_layers.2.ffn.Linear_linear2       131.328k   131.072k  \n",
      "30_encoder_layers.2.norm2.LayerNorm_norm        512.0      256.0  \n",
      "31_decoder_layers.0.self_attn.Linear_wq       65.792k    65.536k  \n",
      "32_decoder_layers.0.self_attn.Linear_wk       65.792k    65.536k  \n",
      "33_decoder_layers.0.self_attn.Linear_wv       65.792k    65.536k  \n",
      "34_decoder_layers.0.self_attn.Linear_wo       65.792k    65.536k  \n",
      "35_decoder_layers.0.norm1.LayerNorm_norm        512.0      256.0  \n",
      "36_decoder_layers.0.enc_dec_attn.Linear_wq    65.792k    65.536k  \n",
      "37_decoder_layers.0.enc_dec_attn.Linear_wk    65.792k    65.536k  \n",
      "38_decoder_layers.0.enc_dec_attn.Linear_wv    65.792k    65.536k  \n",
      "39_decoder_layers.0.enc_dec_attn.Linear_wo    65.792k    65.536k  \n",
      "40_decoder_layers.0.norm2.LayerNorm_norm        512.0      256.0  \n",
      "41_decoder_layers.0.ffn.Linear_linear1       131.584k   131.072k  \n",
      "42_decoder_layers.0.ffn.Dropout_dropout             -          -  \n",
      "43_decoder_layers.0.ffn.Linear_linear2       131.328k   131.072k  \n",
      "44_decoder_layers.0.norm3.LayerNorm_norm        512.0      256.0  \n",
      "45_decoder_layers.1.self_attn.Linear_wq       65.792k    65.536k  \n",
      "46_decoder_layers.1.self_attn.Linear_wk       65.792k    65.536k  \n",
      "47_decoder_layers.1.self_attn.Linear_wv       65.792k    65.536k  \n",
      "48_decoder_layers.1.self_attn.Linear_wo       65.792k    65.536k  \n",
      "49_decoder_layers.1.norm1.LayerNorm_norm        512.0      256.0  \n",
      "50_decoder_layers.1.enc_dec_attn.Linear_wq    65.792k    65.536k  \n",
      "51_decoder_layers.1.enc_dec_attn.Linear_wk    65.792k    65.536k  \n",
      "52_decoder_layers.1.enc_dec_attn.Linear_wv    65.792k    65.536k  \n",
      "53_decoder_layers.1.enc_dec_attn.Linear_wo    65.792k    65.536k  \n",
      "54_decoder_layers.1.norm2.LayerNorm_norm        512.0      256.0  \n",
      "55_decoder_layers.1.ffn.Linear_linear1       131.584k   131.072k  \n",
      "56_decoder_layers.1.ffn.Dropout_dropout             -          -  \n",
      "57_decoder_layers.1.ffn.Linear_linear2       131.328k   131.072k  \n",
      "58_decoder_layers.1.norm3.LayerNorm_norm        512.0      256.0  \n",
      "59_decoder_layers.2.self_attn.Linear_wq       65.792k    65.536k  \n",
      "60_decoder_layers.2.self_attn.Linear_wk       65.792k    65.536k  \n",
      "61_decoder_layers.2.self_attn.Linear_wv       65.792k    65.536k  \n",
      "62_decoder_layers.2.self_attn.Linear_wo       65.792k    65.536k  \n",
      "63_decoder_layers.2.norm1.LayerNorm_norm        512.0      256.0  \n",
      "64_decoder_layers.2.enc_dec_attn.Linear_wq    65.792k    65.536k  \n",
      "65_decoder_layers.2.enc_dec_attn.Linear_wk    65.792k    65.536k  \n",
      "66_decoder_layers.2.enc_dec_attn.Linear_wv    65.792k    65.536k  \n",
      "67_decoder_layers.2.enc_dec_attn.Linear_wo    65.792k    65.536k  \n",
      "68_decoder_layers.2.norm2.LayerNorm_norm        512.0      256.0  \n",
      "69_decoder_layers.2.ffn.Linear_linear1       131.584k   131.072k  \n",
      "70_decoder_layers.2.ffn.Dropout_dropout             -          -  \n",
      "71_decoder_layers.2.ffn.Linear_linear2       131.328k   131.072k  \n",
      "72_decoder_layers.2.norm3.LayerNorm_norm        512.0      256.0  \n",
      "73_fc                                       4.937998M  4.918784M  \n",
      "------------------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          16.584718M\n",
      "Trainable params      16.584718M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds              16.54784M\n",
      "================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\soft_big\\anaconda3\\envs\\torch12\\lib\\site-packages\\torchsummaryX\\torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_src_embedding</th>\n",
       "      <td>[256, 10837]</td>\n",
       "      <td>[128, 25, 256]</td>\n",
       "      <td>2774272.0</td>\n",
       "      <td>2774272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_pos_encoding.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 25, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_tgt_embedding</th>\n",
       "      <td>[256, 19214]</td>\n",
       "      <td>[128, 27, 256]</td>\n",
       "      <td>4918784.0</td>\n",
       "      <td>4918784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_pos_encoding.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 27, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_encoder_layers.0.self_attn.Linear_wq</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[128, 25, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69_decoder_layers.2.ffn.Linear_linear1</th>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>[128, 27, 512]</td>\n",
       "      <td>131584.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70_decoder_layers.2.ffn.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 27, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71_decoder_layers.2.ffn.Linear_linear2</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[128, 27, 256]</td>\n",
       "      <td>131328.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72_decoder_layers.2.norm3.LayerNorm_norm</th>\n",
       "      <td>[256]</td>\n",
       "      <td>[128, 27, 256]</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73_fc</th>\n",
       "      <td>[256, 19214]</td>\n",
       "      <td>[128, 27, 19214]</td>\n",
       "      <td>4937998.0</td>\n",
       "      <td>4918784.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Kernel Shape      Output Shape  \\\n",
       "Layer                                                                      \n",
       "0_src_embedding                           [256, 10837]    [128, 25, 256]   \n",
       "1_pos_encoding.Dropout_dropout                       -    [128, 25, 256]   \n",
       "2_tgt_embedding                           [256, 19214]    [128, 27, 256]   \n",
       "3_pos_encoding.Dropout_dropout                       -    [128, 27, 256]   \n",
       "4_encoder_layers.0.self_attn.Linear_wq      [256, 256]    [128, 25, 256]   \n",
       "...                                                ...               ...   \n",
       "69_decoder_layers.2.ffn.Linear_linear1      [256, 512]    [128, 27, 512]   \n",
       "70_decoder_layers.2.ffn.Dropout_dropout              -    [128, 27, 512]   \n",
       "71_decoder_layers.2.ffn.Linear_linear2      [512, 256]    [128, 27, 256]   \n",
       "72_decoder_layers.2.norm3.LayerNorm_norm         [256]    [128, 27, 256]   \n",
       "73_fc                                     [256, 19214]  [128, 27, 19214]   \n",
       "\n",
       "                                             Params  Mult-Adds  \n",
       "Layer                                                           \n",
       "0_src_embedding                           2774272.0  2774272.0  \n",
       "1_pos_encoding.Dropout_dropout                  NaN        NaN  \n",
       "2_tgt_embedding                           4918784.0  4918784.0  \n",
       "3_pos_encoding.Dropout_dropout                  NaN        NaN  \n",
       "4_encoder_layers.0.self_attn.Linear_wq      65792.0    65536.0  \n",
       "...                                             ...        ...  \n",
       "69_decoder_layers.2.ffn.Linear_linear1     131584.0   131072.0  \n",
       "70_decoder_layers.2.ffn.Dropout_dropout         NaN        NaN  \n",
       "71_decoder_layers.2.ffn.Linear_linear2     131328.0   131072.0  \n",
       "72_decoder_layers.2.norm3.LayerNorm_norm      512.0      256.0  \n",
       "73_fc                                     4937998.0  4918784.0  \n",
       "\n",
       "[74 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src, tgt = next(iter(train_dataloader))\n",
    "src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "\n",
    "src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])\n",
    "\n",
    "tgt_input = tgt[:, :-1]\n",
    "tgt_output = tgt[:, 1:]\n",
    "tgt_mask = generate_tgt_mask(tgt_input, DE_VOCAB['<pad>'])\n",
    "\n",
    "summary(model, src, tgt_input, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    对模型进行一个epoch的训练。\n",
    "\n",
    "    参数:\n",
    "    model: 训练的模型。\n",
    "    dataloader: 数据加载器，提供训练数据。\n",
    "    optimizer: 优化器，用于更新模型参数。\n",
    "    criterion: 损失函数。\n",
    "    device: 训练使用的设备（CPU或GPU）。\n",
    "\n",
    "    返回:\n",
    "    float: 该epoch的平均损失。\n",
    "    \"\"\"\n",
    "    model.train()  # 将模型设置为训练模式\n",
    "    total_loss = 0  # 记录总损失\n",
    "\n",
    "    # 使用tqdm库显示训练进度条\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Train')\n",
    "\n",
    "    for i, (src, tgt) in enumerate(dataloader):\n",
    "        # 将数据移动到指定的设备上\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        # 生成源序列和目标序列的掩码\n",
    "        src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        tgt_mask = generate_tgt_mask(tgt_input, DE_VOCAB['<pad>'])\n",
    "\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "        # 使用混合精度训练\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            loss = criterion(output.reshape(-1, output.size(2)), tgt_output.reshape(-1))\n",
    "\n",
    "        # 反向传播和优化\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()  # 更新学习率\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # 更新进度条\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(total_loss / (i + 1)),\n",
    "            lr=\"{:.09f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        batch_bar.update()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, DEVICE):\n",
    "    \"\"\"\n",
    "    对模型进行一个epoch的验证。\n",
    "\n",
    "    参数:\n",
    "    model: 需要验证的模型。\n",
    "    dataloader: 数据加载器，提供验证数据。\n",
    "    criterion: 损失函数。\n",
    "    DEVICE: 验证使用的设备（CPU或GPU）。\n",
    "\n",
    "    返回:\n",
    "    tuple: 包含平均损失和平均BLEU分数的元组。\n",
    "    \"\"\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    epoch_loss = 0\n",
    "    epoch_bleu_score = 0\n",
    "\n",
    "    # 使用tqdm库显示验证进度条\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Validate')\n",
    "\n",
    "    with torch.no_grad():  # 在验证过程中不计算梯度\n",
    "        for i, (src, tgt) in enumerate(dataloader):\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            tgt_mask = generate_tgt_mask(tgt_input, DE_VOCAB['<pad>'])\n",
    "\n",
    "            # 使用混合精度评估\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "                loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            # 计算并累加BLEU分数\n",
    "            epoch_bleu_score += calculate_bleu(tgt_output, output.argmax(-1))\n",
    "\n",
    "            # 更新进度条\n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(epoch_loss / (i + 1)),\n",
    "                bleu=\"{:.04f}\".format(epoch_bleu_score / (i + 1)))\n",
    "            batch_bar.update()\n",
    "\n",
    "    # 计算平均损失和BLEU分数\n",
    "    epoch_loss /= len(dataloader)\n",
    "    epoch_bleu_score /= len(dataloader)\n",
    "\n",
    "    return epoch_loss, epoch_bleu_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, src, de_tokenizer):\n",
    "    \"\"\"\n",
    "    使用训练好的模型进行推理，生成目标语言序列。\n",
    "\n",
    "    参数:\n",
    "    model: 训练好的Transformer模型。\n",
    "    src (Tensor): 源语言序列的张量。\n",
    "    de_tokenizer: 目标语言的词汇表，用于将索引转换为单词。\n",
    "\n",
    "    返回:\n",
    "    list: 生成的目标语言句子列表。\n",
    "    \"\"\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "\n",
    "    src_mask = generate_src_mask(src, EN_VOCAB['<pad>'])  # 生成源序列的掩码\n",
    "\n",
    "    # 使用<sos>标记初始化目标输入张量\n",
    "    tgt_input = torch.full((src.size(0), 1), DE_VOCAB['<sos>'], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # 为批处理中的每个序列创建一个结束标志\n",
    "    eos_flags = torch.zeros(src.size(0), dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "    # 对每个目标令牌进行推理\n",
    "    with torch.no_grad():\n",
    "        for _ in range(70):  # 最多生成70个令牌\n",
    "            tgt_mask = generate_tgt_mask(tgt_input, DE_VOCAB['<pad>'])  # 生成目标序列的掩码\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            next_tokens = output.argmax(2)[:, -1].unsqueeze(1)  # 选择概率最高的下一个令牌\n",
    "            tgt_input = torch.cat((tgt_input, next_tokens), dim=1)  # 将下一个令牌添加到目标输入中\n",
    "\n",
    "            # 更新已生成<eos>标记的序列的结束标志\n",
    "            eos_flags |= (next_tokens.squeeze() == DE_VOCAB['<eos>'])\n",
    "            # 如果所有序列都已生成<eos>或达到最大长度，则停止生成\n",
    "            if torch.all(eos_flags):\n",
    "                break\n",
    "\n",
    "    # 将目标输入张量转换为翻译后的句子\n",
    "    translated_sentences = []\n",
    "    for i in range(tgt_input.size(0)):\n",
    "        translated_tokens = []\n",
    "        for token in tgt_input[i][1:]:  # 跳过第一个<sos>标记\n",
    "            if token == DE_VOCAB['<eos>']:\n",
    "                break  # 遇到<eos>标记时停止\n",
    "            else:\n",
    "                translated_tokens.append(DE_VOCAB.itos[token.item()])  # 将索引转换为单词\n",
    "\n",
    "        translated_sentence = ' '.join(translated_tokens)  # 将单词列表连接成句子\n",
    "        translated_sentences.append(translated_sentence)\n",
    "\n",
    "    return translated_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开启训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.8183 | Val Loss: 4.2099 | BLEU Score: 7.6717\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.8065 | Val Loss: 3.6510 | BLEU Score: 12.0534\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3156 | Val Loss: 3.3265 | BLEU Score: 15.4623\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9344 | Val Loss: 3.1600 | BLEU Score: 16.3336\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.6752 | Val Loss: 3.0981 | BLEU Score: 26.6629\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4760 | Val Loss: 3.0695 | BLEU Score: 19.6995\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3194 | Val Loss: 3.0351 | BLEU Score: 20.0697\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1872 | Val Loss: 3.0281 | BLEU Score: 18.8433\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0844 | Val Loss: 3.0505 | BLEU Score: 24.5782\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0042 | Val Loss: 3.0385 | BLEU Score: 31.7693\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9423 | Val Loss: 3.0605 | BLEU Score: 27.6693\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8876 | Val Loss: 3.0692 | BLEU Score: 28.5538\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8453 | Val Loss: 3.1014 | BLEU Score: 21.0291\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8060 | Val Loss: 3.1120 | BLEU Score: 27.8949\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7739 | Val Loss: 3.1276 | BLEU Score: 25.6422\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7478 | Val Loss: 3.1507 | BLEU Score: 26.5843\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7228 | Val Loss: 3.1590 | BLEU Score: 25.8857\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7011 | Val Loss: 3.1746 | BLEU Score: 26.1551\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6819 | Val Loss: 3.1813 | BLEU Score: 23.9430\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6643 | Val Loss: 3.2126 | BLEU Score: 24.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')  # 记录最佳验证损失值\n",
    "train_losses = []  # 存储每个epoch的训练损失\n",
    "val_losses = []  # 存储每个epoch的验证损失\n",
    "bleu_scores = []  # 存储每个epoch的BLEU分数\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # 训练\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, DEVICE)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # 验证\n",
    "    val_loss, bleu_score = validate_epoch(model, val_dataloader, criterion, DEVICE)\n",
    "    val_losses.append(val_loss)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "    # 如果当前验证损失低于之前的最佳值，则保存模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估test集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bleu_score\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m test_bleu \u001b[38;5;241m=\u001b[39m evaluate_test_set_bleu(\u001b[43mmodel\u001b[49m, test_dataloader, de_tokenizer)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest BLEU score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_bleu\u001b[38;5;241m.\u001b[39mscore)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_test_set_bleu(model, test_dataloader, de_tokenizer):\n",
    "    \"\"\"\n",
    "    在测试集上评估模型的BLEU分数。\n",
    "\n",
    "    参数:\n",
    "    model: 训练好的Transformer模型。\n",
    "    test_dataloader: 测试数据的数据加载器。\n",
    "    de_tokenizer: 目标语言的词汇表。\n",
    "\n",
    "    返回:\n",
    "    float: 测试集的BLEU分数。\n",
    "    \"\"\"\n",
    "    translated_sentences = []\n",
    "    ground_truth_sentences = []\n",
    "\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        src, tgt_output = batch\n",
    "        src, tgt = src.to(DEVICE), tgt_output.to(DEVICE)\n",
    "        tgt_sentences = [' '.join([DE_VOCAB.itos[token.item()] for token in sequence if token.item() not in [DE_VOCAB['<pad>'], DE_VOCAB['<sos>'], DE_VOCAB['<eos>']]]) for sequence in tgt_output]\n",
    "\n",
    "        translations = inference(model, src, de_tokenizer)\n",
    "        translated_sentences.extend(translations)\n",
    "        ground_truth_sentences.extend([[tgt] for tgt in tgt_sentences])\n",
    "        \n",
    "    rand_index = random.randint(0, len(test_dataset))\n",
    "    print(\"\\n\\nExample Sentence and its Translation\")\n",
    "    print(\"Source Sentence in English               :\", ' '.join([EN_VOCAB.itos[i] for i in test_dataset[rand_index][0] if EN_VOCAB.itos[i] not in ['<pad>', '<sos>', '<eos>']]))\n",
    "    print(\"Ground Truth Sentence in German          :\", ground_truth_sentences[rand_index][0])\n",
    "    print(\"Machine Translated Sentence in German    :\", translated_sentences[rand_index])\n",
    "\n",
    "    bleu_score = sacrebleu.corpus_bleu(translated_sentences, ground_truth_sentences)\n",
    "    return bleu_score\n",
    "\n",
    "# Usage example\n",
    "test_bleu = evaluate_test_set_bleu(model, test_dataloader, de_tokenizer)\n",
    "print(\"Test BLEU score:\", test_bleu.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29000/29000 [00:00<00:00, 38090.01it/s]                           \n",
      "100%|██████████| 29000/29000 [00:00<00:00, 29507.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocab Size English 10837\n",
      "\n",
      "Vocab Size German 19214\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (31) must match the size of tensor b (256) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 948\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[1;32m--> 948\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# 验证\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 816\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;66;03m# 使用混合精度训练\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m--> 816\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)), tgt_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    819\u001b[0m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n",
      "File \u001b[1;32me:\\soft_big\\anaconda3\\envs\\torch12\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\soft_big\\anaconda3\\envs\\torch12\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 611\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m    607\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding(tgt)\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m#测试对解码器的输入tgt进行mask，防止残差泄露信息\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[43mtgt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m# 依次通过编码器层\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (31) must match the size of tensor b (256) at non-singleton dimension 3"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
